{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abisubramanya27/CS6910_Assignment2/blob/main/partA/src/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXXJfnO-jhpq",
        "outputId": "7e9b09c3-2206-4a42-e390-4bf177aaca5e"
      },
      "source": [
        "# Mounting drive to store dataset\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0EP3CrxEbJi",
        "outputId": "2a3d0da0-89e6-4030-dc0e-24dfee6ea95f"
      },
      "source": [
        "%cd gdrive/MyDrive/assignments/cs6910/A2/Data\n",
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1H4LUGHYi_ivI7p5xWjyrjFojgIGEh9Jd/cs6910/A2/Data\n",
            "/content/gdrive/.shortcut-targets-by-id/1H4LUGHYi_ivI7p5xWjyrjFojgIGEh9Jd/cs6910/A2/Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ejl6wzuRCBS"
      },
      "source": [
        "# !pip install split-folders"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHtrVxShEOOa"
      },
      "source": [
        "# import splitfolders\n",
        "\n",
        "# # Splitting the training data into training and validation set\n",
        "# splitfolders.ratio('./inaturalist_12K/train', output='./inaturalist_12K/output', seed=1337, ratio=(.9, .1), group_prefix=None)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgiGx6yCuB-Q",
        "outputId": "8683decf-b4b2-46e1-a844-f891193863eb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(physical_devices))\n",
        "\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdy2ocN-wnil"
      },
      "source": [
        "def build_model_partA(inp_img_shape, K_list, F_list, no_neurons_dense, no_classes = 10, activation_fn_list = ['relu']*6, \n",
        "                      P_list = ['valid']*10, S_list = [1]*10, BN_yes = False, dropout_p = 0):\n",
        "    '''\n",
        "    Function to build the model comprising (5 conv+relu+maxpooling layers + 1 dense FC layer) for part A in keras\n",
        "    Arguments :\n",
        "        inp_img_shape -- shape of input image\n",
        "        K_list -- List of number of filters in each non FC layer\n",
        "        F_list -- List of size of filters (assumed same dimension in width and height) in each non FC layer  \n",
        "        no_neurons_dense -- Number of neurons in the dense FC layer\n",
        "        no_classes -- Number of output classes in the classification problem\n",
        "        activation_fn_list -- List of activation function in each convolution and FC layer\n",
        "        P_list -- List of padding options in each non FC layer \n",
        "                  ('valid' : no padding, 'same' : padding to make input and output same dimensions)\n",
        "        S_list -- List of strides (assumed equal in width and height) in each non FC layer\n",
        "        BN_yes -- True : Batch normalisation (BN) should be used, False : BN should not be used\n",
        "        dropout_p -- Probability of dropping out a neuron\n",
        "                     (The dropout is added for the single dense hidden layer alone after referring to many CNN architecture papers)\n",
        "\n",
        "    Returns :\n",
        "        model -- The keras sequential model of the CNN created\n",
        "    '''\n",
        "    model = Sequential()\n",
        "    # First layer\n",
        "    model.add(Conv2D(filters = K_list[0], kernel_size = (F_list[0], F_list[0]), strides = (S_list[0], S_list[0]), \n",
        "                     padding = P_list[0], input_shape = inp_img_shape))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation_fn_list[0]))\n",
        "    model.add(MaxPooling2D(pool_size=(F_list[1], F_list[1]), strides = (S_list[1], S_list[1]), padding = P_list[1]))\n",
        "\n",
        "    # 4 Conv-relu-MaxPooling layers\n",
        "    for l in range(1, 5):\n",
        "        model.add(Conv2D(filters = K_list[2*l], kernel_size = (F_list[2*l], F_list[2*l]), strides = (S_list[2*l], S_list[2*l]), \n",
        "                         padding = P_list[2*l]))\n",
        "        if BN_yes:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Activation(activation_fn_list[l]))\n",
        "        model.add(MaxPooling2D(pool_size = (F_list[2*l+1], F_list[2*l+1]), strides = (S_list[2*l+1], S_list[2*l+1]), padding = P_list[2*l+1]))\n",
        "    \n",
        "    # 1 dense FC layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(dropout_p))\n",
        "    model.add(Dense(units = no_neurons_dense))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation = activation_fn_list[5]))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(units = no_classes))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejgmFIPE_DL5",
        "outputId": "98d382dd-8f00-413e-ff55-5447a541f287"
      },
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login 6746f968d95eb71e281d6c7772a0469574430408"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: wandb in /usr/local/lib/python3.7/dist-packages (0.10.23)\n",
            "Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caaNOC3GEDAX"
      },
      "source": [
        "def data_generator(train_data_path, inp_img_shape, batch_size, data_augment_yes = False, val_data_path = None, test_data_path = None):\n",
        "    # Techniques for data augmentation sent to ImageDataGenerator \n",
        "    data_augment_params = {\n",
        "        'rotation_range': 30,\n",
        "        'height_shift_range': 0.15,\n",
        "        'width_shift_range': 0.15,\n",
        "        #'channel_shift_range': 10,\n",
        "        #'shear_range': 0.15,\n",
        "        #'zoom_range': 0.2,\n",
        "        'horizontal_flip': True \n",
        "    }\n",
        "\n",
        "    train_gen_param = data_augment_params if data_augment_yes else dict()\n",
        "\n",
        "    # Generators for training, validation and test set image data for Part-A from the respective \n",
        "    train_generator = ImageDataGenerator(rescale = 1./255, **train_gen_param).flow_from_directory(train_data_path, \n",
        "                                                                                                  target_size = inp_img_shape[:-1], \n",
        "                                                                                                  batch_size = batch_size, \n",
        "                                                                                                  class_mode = 'categorical')\n",
        "    val_generator = None\n",
        "    if val_data_path is not None:\n",
        "        val_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_data_path, target_size = inp_img_shape[:-1], \n",
        "                                                                                 batch_size = batch_size, class_mode = 'categorical')  \n",
        "    test_generator = None\n",
        "    if test_data_path is not None:\n",
        "        test_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_data_path, target_size = inp_img_shape[:-1], \n",
        "                                                                                  batch_size = batch_size, class_mode = 'categorical')\n",
        "    \n",
        "    return train_generator, val_generator, test_generator\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COdHx5_sFEAr"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "config_1 = {\n",
        "    \"learning_rate\": 5e-3,\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 64,\n",
        "    \"loss_function\": 'categorical_crossentropy',\n",
        "    \"architecture\": 'CNN',\n",
        "    \"dataset\": \"iNaturalist_12K\"\n",
        "}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eOL2KSnGffH"
      },
      "source": [
        "import math\n",
        "\n",
        "def train_model(model, train_size, train_gen, config, data_augment_yes = False, val_gen = None):\n",
        "    model.compile(optimizer = Adam(learning_rate=config['learning_rate']), loss = config['loss_function'], metrics = ['accuracy'])\n",
        "    steps_per_epoch = math.ceil(1.0 * train_size / config['batch_size'])\n",
        "    steps_per_epoch += math.ceil(1024.0 / config['batch_size']) * (data_augment_yes == True)\n",
        "\n",
        "    model.fit(train_gen,\n",
        "              epochs = config['epochs'], \n",
        "              steps_per_epoch = steps_per_epoch,\n",
        "              validation_data = val_gen,\n",
        "              verbose = 2,\n",
        "              callbacks = [WandbCallback()])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "R2In7LU6GaOr",
        "outputId": "e5324239-15fb-4900-fae2-2bcc0092ffc5"
      },
      "source": [
        "# Running sample run\n",
        "\n",
        "def CNN(inp_img_shape, train_data_path, K_list, F_list, no_neurons_dense, config, no_classes = 10, activation_fn_list = ['relu']*6, \n",
        "        P_list = ['valid']*10, S_list = [1]*10, BN_yes = False, dropout_p = 0, val_data_path = None, test_data_path = None, \n",
        "        data_augment_yes = False):\n",
        "    \n",
        "    run = wandb.init(project=\"assignment2\", entity=\"abisheks\", reinit=True, config=config)\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    model = build_model_partA(inp_img_shape, K_list, F_list, no_neurons_dense, no_classes, activation_fn_list, P_list, S_list, BN_yes, dropout_p)\n",
        "    # model.summary()\n",
        "    train_gen, val_gen, test_gen = data_generator(train_data_path, inp_img_shape, config['batch_size'], data_augment_yes, \n",
        "                                                  val_data_path, test_data_path)\n",
        "    train_size = train_gen.samples\n",
        "    model = train_model(model, train_size, train_gen, config, data_augment_yes, val_gen)\n",
        "    \n",
        "    run.finish()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Hyperparameters for building the model for Part-A\n",
        "K_list_1 = [32, 32, 32, 32, 64, 64, 64, 64, 128, 128]       # List of number of filters in each non FC layer\n",
        "F_list_1 = [11, 3, 5, 3, 3, 3, 3, 3, 3, 3]                  # List of size of filters in each non FC layer  \n",
        "no_neurons_dense_1 = 128                                    # Number of neurons in the dense FC layer\n",
        "activation_fn_list_1 = ['relu']*6                           # List of activation function in each convolution and FC layer\n",
        "P_list_1 = ['valid']*10                                     # List of padding options in each non FC layer ('valid' : no padding, 'same' : padding to make input and output same dimensions)\n",
        "S_list_1 = [4, 2, 1, 1, 1, 1, 1, 2, 1, 1]                   # List of number of strides in each non FC layer\n",
        "inp_img_shape_1 = (227, 227, 3)                             # Shape of input image from data\n",
        "no_classes_1 = 10                                           # Number of output classes in the classification problem\n",
        "BN_1 = True                                                 # True : Batch normalisation (BN) should be used, False : BN should not be used\n",
        "dropout_p_1 = 0.3                                           # Probability of dropping out a neuron\n",
        "\n",
        "\n",
        "# PART-A, Question 1 -- Building a model with (5 conv+relu+maxpooling layers + 1 dense FC layer) for image classification objective \n",
        "modelA = CNN(inp_img_shape_1, './inaturalist_12K/train', K_list_1, F_list_1, no_neurons_dense_1, config_1, no_classes_1, \n",
        "             activation_fn_list_1, P_list_1, S_list_1, BN_1, dropout_p_1, './inaturalist_12K/val', './inaturalist_12K/test', False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.23<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">upbeat-pond-31</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment2\" target=\"_blank\">https://wandb.ai/abisheks/assignment2</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/abisheks/assignment2/runs/x9ls9j4a\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/x9ls9j4a</a><br/>\n",
              "                Run data is saved locally in <code>/content/gdrive/.shortcut-targets-by-id/1H4LUGHYi_ivI7p5xWjyrjFojgIGEh9Jd/cs6910/A2/Data/wandb/run-20210330_203758-x9ls9j4a</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found 9006 images belonging to 10 classes.\n",
            "Found 1004 images belonging to 10 classes.\n",
            "Found 2008 images belonging to 10 classes.\n",
            "Epoch 1/10\n",
            "141/141 - 115s - loss: 2.1962 - accuracy: 0.2142 - val_loss: 5.0933 - val_accuracy: 0.1643\n",
            "Epoch 2/10\n",
            "141/141 - 113s - loss: 2.0381 - accuracy: 0.2759 - val_loss: 2.4603 - val_accuracy: 0.2181\n",
            "Epoch 3/10\n",
            "141/141 - 114s - loss: 1.9997 - accuracy: 0.2867 - val_loss: 2.8381 - val_accuracy: 0.1594\n",
            "Epoch 4/10\n",
            "141/141 - 114s - loss: 1.9449 - accuracy: 0.3067 - val_loss: 2.3630 - val_accuracy: 0.1932\n",
            "Epoch 5/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSwVfR6wfthS"
      },
      "source": [
        "!find \"./inaturalis\" -size 0 -print"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
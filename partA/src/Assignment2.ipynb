{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abisubramanya27/CS6910_Assignment2/blob/main/partA/src/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXXJfnO-jhpq"
      },
      "source": [
        "# Mounting drive to store dataset\n",
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/gdrive')\n",
        "#!rm -rf inaturalist_12K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0EP3CrxEbJi",
        "outputId": "7e291ed0-4c26-4f51-dc00-16cd5698c90a"
      },
      "source": [
        "%%time\n",
        "# %cd gdrive/MyDrive/assignments/cs6910/A2/Data\n",
        "# !pwd\n",
        "#!gdown --id 11SGStqp8Vug2GDzSpJDwQYHThLIjZFQn\n",
        "\n",
        "!unzip -q inaturalist_12K.zip\n",
        "!ls\n",
        "\n",
        "# import zipfile\n",
        "# import concurrent.futures\n",
        "\n",
        "# zf = zipfile.ZipFile('inaturalist_12K.zip')\n",
        "\n",
        "# def unzip(file):\n",
        "#     zf.extract(file)\n",
        "\n",
        "# with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "#     executor.map(unzip, zf.infolist())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inaturalist_12K  inaturalist_12K.zip  sample_data  wandb\n",
            "CPU times: user 888 ms, sys: 118 ms, total: 1.01 s\n",
            "Wall time: 2min 56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ejl6wzuRCBS"
      },
      "source": [
        "# !pip install split-folders"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHtrVxShEOOa"
      },
      "source": [
        "# import splitfolders\n",
        "\n",
        "# # Splitting the training data into training and validation set\n",
        "# splitfolders.ratio('./inaturalist_12K/train', output='./inaturalist_12K/output', seed=1337, ratio=(.9, .1), group_prefix=None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgiGx6yCuB-Q",
        "outputId": "aa84d414-3c76-4b8c-d4c5-d4ce2b93c82f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(physical_devices))\n",
        "\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdy2ocN-wnil"
      },
      "source": [
        "def build_model_partA(inp_img_shape, K_list, F_list, no_neurons_dense, no_classes = 10, activation_fn_list = ['relu']*6, \n",
        "                      P_list = ['valid']*10, S_list = [1]*10, BN_yes = False, dropout_p = 0):\n",
        "    '''\n",
        "    Function to build the model comprising (5 conv+relu+maxpooling layers + 1 dense FC layer) for part A in keras\n",
        "    Arguments :\n",
        "        inp_img_shape -- shape of input image\n",
        "        K_list -- List of number of filters in each non FC layer\n",
        "        F_list -- List of size of filters (assumed same dimension in width and height) in each non FC layer  \n",
        "        no_neurons_dense -- Number of neurons in the dense FC layer\n",
        "        no_classes -- Number of output classes in the classification problem\n",
        "        activation_fn_list -- List of activation function in each convolution and FC layer\n",
        "        P_list -- List of padding options in each non FC layer \n",
        "                  ('valid' : no padding, 'same' : padding to make input and output same dimensions)\n",
        "        S_list -- List of strides (assumed equal in width and height) in each non FC layer\n",
        "        BN_yes -- True : Batch normalisation (BN) should be used, False : BN should not be used\n",
        "        dropout_p -- Probability of dropping out a neuron\n",
        "                     (The dropout is added for the single dense hidden layer alone after referring to many CNN architecture papers)\n",
        "\n",
        "    Returns :\n",
        "        model -- The keras sequential model of the CNN created\n",
        "    '''\n",
        "    model = Sequential()\n",
        "    # First layer\n",
        "    model.add(Conv2D(filters = K_list[0], kernel_size = (F_list[0], F_list[0]), strides = (S_list[0], S_list[0]), \n",
        "                     padding = P_list[0], input_shape = inp_img_shape))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation_fn_list[0]))\n",
        "    model.add(MaxPooling2D(pool_size=(F_list[1], F_list[1]), strides = (S_list[1], S_list[1]), padding = P_list[1]))\n",
        "\n",
        "    # 4 Conv-relu-MaxPooling layers\n",
        "    for l in range(1, 5):\n",
        "        model.add(Conv2D(filters = K_list[2*l], kernel_size = (F_list[2*l], F_list[2*l]), strides = (S_list[2*l], S_list[2*l]), \n",
        "                         padding = P_list[2*l]))\n",
        "        if BN_yes:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Activation(activation_fn_list[l]))\n",
        "        model.add(MaxPooling2D(pool_size = (F_list[2*l+1], F_list[2*l+1]), strides = (S_list[2*l+1], S_list[2*l+1]), padding = P_list[2*l+1]))\n",
        "    \n",
        "    # 1 dense FC layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(dropout_p))\n",
        "    model.add(Dense(units = no_neurons_dense))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation = activation_fn_list[5]))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(units = no_classes))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejgmFIPE_DL5",
        "outputId": "9f888648-57f8-4cc4-f04e-d48126697cc0"
      },
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login 6746f968d95eb71e281d6c7772a0469574430408"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: wandb in /usr/local/lib/python3.7/dist-packages (0.10.24)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied, skipping upgrade: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T99QShvaRdXa"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Model for resizing and rescaling images\n",
        "image_rescale = Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "# Model for performing random transformations for data augmentation\n",
        "data_augmentation = Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomTranslation(0.2, 0.2),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2, 0.2),\n",
        "    layers.experimental.preprocessing.RandomContrast(0.2)\n",
        "])\n",
        "\n",
        "def prepare_data(data_path, inp_img_shape, batch_size, img_preprocess, data_augmentation, data_augment_yes = False, shuffle = True):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    dataset = image_dataset_from_directory(\n",
        "        data_path, labels='inferred', color_mode='rgb', batch_size=batch_size, image_size=inp_img_shape[:-1], shuffle=shuffle,\n",
        "        label_mode = 'categorical'\n",
        "    )\n",
        "    \n",
        "    dataset = dataset.map(lambda x, y: (img_preprocess(x), y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # Use data augmentation only if data_augment_yes == True (Training set only requires data augmentation)\n",
        "    if data_augment_yes:\n",
        "        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # Use buffered prefecting on datasets\n",
        "    return dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "def data_generator(train_data_path, inp_img_shape, batch_size, data_augment_yes = False, val_data_path = None, test_data_path = None):\n",
        "    train_data = prepare_data(train_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, data_augment_yes)\n",
        "    val_data = None\n",
        "    if val_data_path is not None:\n",
        "        val_data = prepare_data(val_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, False)\n",
        "    test_data = None\n",
        "    if test_data_path is not None:\n",
        "        test_data = prepare_data(test_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, False)\n",
        "    \n",
        "    return train_data, val_data, test_data\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caaNOC3GEDAX"
      },
      "source": [
        "# def data_generator(train_data_path, inp_img_shape, batch_size, data_augment_yes = False, val_data_path = None, test_data_path = None):\n",
        "#     # Techniques for data augmentation sent to ImageDataGenerator \n",
        "#     data_augment_params = {\n",
        "#         'rotation_range': 25,\n",
        "#         'height_shift_range': 0.2,\n",
        "#         'width_shift_range': 0.2,\n",
        "#         'channel_shift_range': 40,\n",
        "#         'brightness_range': (0.2, 0.7),\n",
        "#         'zoom_range': 0.2,\n",
        "#         'horizontal_flip': True \n",
        "#     }\n",
        "\n",
        "#     train_gen_param = data_augment_params if data_augment_yes else dict()\n",
        "\n",
        "#     # Generators for training, validation and test set image data for Part-A from the respective \n",
        "#     train_generator = ImageDataGenerator(rescale = 1./255, **train_gen_param).flow_from_directory(train_data_path, \n",
        "#                                                                                                   target_size = inp_img_shape[:-1], \n",
        "#                                                                                                   batch_size = batch_size, \n",
        "#                                                                                                   class_mode = 'categorical')\n",
        "#     val_generator = None\n",
        "#     if val_data_path is not None:\n",
        "#         val_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_data_path, target_size = inp_img_shape[:-1], \n",
        "#                                                                                  batch_size = batch_size, class_mode = 'categorical')  \n",
        "#     test_generator = None\n",
        "#     if test_data_path is not None:\n",
        "#         test_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_data_path, target_size = inp_img_shape[:-1], \n",
        "#                                                                                   batch_size = batch_size, class_mode = 'categorical')\n",
        "    \n",
        "#     return train_generator, val_generator, test_generator\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COdHx5_sFEAr"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "config_1 = {\n",
        "    \"learning_rate\": 5e-3,\n",
        "    \"epochs\": 20,\n",
        "    \"batch_size\": 64,\n",
        "    \"loss_function\": 'categorical_crossentropy',\n",
        "    \"architecture\": 'CNN',\n",
        "    \"dataset\": \"iNaturalist_12K\"\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eOL2KSnGffH"
      },
      "source": [
        "import math\n",
        "\n",
        "def train_model(model, train_data, config, val_data = None):\n",
        "    model.compile(optimizer = Adam(learning_rate=config['learning_rate']), loss = config['loss_function'], metrics = ['accuracy'])\n",
        "    model.fit(train_data,\n",
        "              epochs = config['epochs'], \n",
        "              validation_data = val_data,\n",
        "              verbose = 2,\n",
        "              callbacks = [WandbCallback()])\n",
        "    \n",
        "    return model\n",
        "\n",
        "def get_klist(method, start1):\n",
        "  if method == 'same':\n",
        "    return [start] * 10\n",
        "  elif method == 'double':\n",
        "    start = start1\n",
        "    vals = []\n",
        "    for i in range(5):\n",
        "      vals.append(start)\n",
        "      vals.append(start)\n",
        "      start *= 2\n",
        "    return vals\n",
        "  else:\n",
        "    start = start1\n",
        "    vals = []\n",
        "    for i in range(5):\n",
        "      vals.append(start)\n",
        "      vals.append(start)\n",
        "      start = max(start//2, 1)\n",
        "    return vals"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2In7LU6GaOr"
      },
      "source": [
        "# Running sample run\n",
        "\n",
        "def CNN(inp_img_shape, train_data_path, K_list, F_list, no_neurons_dense, config, no_classes = 10, activation_fn_list = ['relu']*6, \n",
        "        P_list = ['valid']*10, S_list = [1]*10, BN_yes = False, dropout_p = 0, val_data_path = None, test_data_path = None, \n",
        "        data_augment_yes = False):\n",
        "    \n",
        "    #run = wandb.init(project=\"assignment2\", entity=\"abisheks\", reinit=True, config=config)\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    model = build_model_partA(inp_img_shape, K_list, F_list, no_neurons_dense, no_classes, activation_fn_list, P_list, S_list, BN_yes, dropout_p)\n",
        "    # model.summary()\n",
        "    train_gen, val_gen, test_gen = data_generator(train_data_path, inp_img_shape, config['batch_size'], data_augment_yes, \n",
        "                                                  val_data_path, test_data_path)\n",
        "    model = train_model(model, train_gen, config, val_gen)\n",
        "    \n",
        "    #run.finish()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Hyperparameters for building the model for Part-A\n",
        "K_list_1 = [32, 32, 32, 32, 64, 64, 64, 64, 128, 128]       # List of number of filters in each non FC layer\n",
        "F_list_1 = [11, 3, 5, 3, 3, 3, 3, 3, 3, 3]                  # List of size of filters in each non FC layer  \n",
        "no_neurons_dense_1 = 256                                    # Number of neurons in the dense FC layer\n",
        "activation_fn_list_1 = ['relu']*6                           # List of activation function in each convolution and FC layer\n",
        "P_list_1 = ['valid']*10                                     # List of padding options in each non FC layer ('valid' : no padding, 'same' : padding to make input and output same dimensions)\n",
        "S_list_1 = [4, 2, 1, 1, 1, 1, 1, 2, 1, 1]                   # List of number of strides in each non FC layer\n",
        "inp_img_shape_1 = (227, 227, 3)                             # Shape of input image from data\n",
        "no_classes_1 = 10                                           # Number of output classes in the classification problem\n",
        "BN_1 = True                                                 # True : Batch normalisation (BN) should be used, False : BN should not be used\n",
        "dropout_p_1 = 0.3                                           # Probability of dropping out a neuron\n",
        "\n",
        "\n",
        "# PART-A, Question 1 -- Building a model with (5 conv+relu+maxpooling layers + 1 dense FC layer) for image classification objective \n",
        "# = CNN(inp_img_shape_1, './inaturalist_12K/train', K_list_1, F_list_1, no_neurons_dense_1, config_1, no_classes_1, \n",
        "#             activation_fn_list_1, P_list_1, S_list_1, BN_1, dropout_p_1, './inaturalist_12K/val', './inaturalist_12K/test', False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSwVfR6wfthS"
      },
      "source": [
        "sweep_config = {\n",
        "    'name': 'CNN',\n",
        "    'method': 'bayes',                   # Possible search : grid, random, bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'no_filters': {\n",
        "            'values': [32, 64]\n",
        "        },\n",
        "        'filter_organization': {\n",
        "            'values': ['same', 'double', 'half']\n",
        "        },\n",
        "        'data_augmented': {\n",
        "            'values': [True, False]\n",
        "        },\n",
        "        'dropout' :{\n",
        "            'values': [0.2, 0.3]\n",
        "        },\n",
        "        'batch_normalization': {\n",
        "            'values': [True, False]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnCtc0c2eMqR"
      },
      "source": [
        "def sweep_wrapper(data_path = './inaturalist_12K'):\n",
        "  \n",
        "  # Wrapper function to call the CNN function for sweeping with different hyperparameters\n",
        "  # loss - (string) Loss function used. Takes values only in ['cross-entropy', 'squared-error']\n",
        "\n",
        "  # Default values for hyper-parameters we're going to sweep over\n",
        "  config_defaults =  {\n",
        "      'no_filters': 32,\n",
        "      'filter_organization': 'same',\n",
        "      'data_augmented': True, \n",
        "      'dropout' : 0.2,\n",
        "      'batch_normalization': True,\n",
        "  }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  run = wandb.init(config=config_defaults, reinit=True)\n",
        "  \n",
        "  # Config is a variable that holds and saves hyperparameters and inputs\n",
        "  config = wandb.config\n",
        "\n",
        "  wandb.run.name = f'nf_{config.no_filters}_fo_{config.filter_organization}_dr_{config.dropout}\\\n",
        "                    _da_{config.data_augmented}_bn_{config.batch_normalization}'\n",
        "  wandb.run.save()\n",
        "\n",
        "  # Sweep uses L2 regularisation as default as given in the question\n",
        "  modelA = CNN(inp_img_shape_1, f'{data_path}/train', get_klist(config.filter_organization, config.no_filters), F_list_1,\n",
        "               no_neurons_dense_1, config_1, no_classes_1, activation_fn_list_1, P_list_1, S_list_1, config.batch_normalization, \n",
        "               config.dropout, f'{data_path}/val', f'{data_path}/test', config.data_augmented)\n",
        "  run.finish()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "NL25cORLeRto",
        "outputId": "aa25617b-c8e0-4de3-b37e-9f808194292d"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity=\"abisheks\", project=\"assignment2\")\n",
        "wandb.agent(sweep_id, lambda : sweep_wrapper())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: mghk051h\n",
            "Sweep URL: https://wandb.ai/abisheks/assignment2/sweeps/mghk051h\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q84iklqp with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmented: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organization: double\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_filters: 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.24<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">exalted-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment2\" target=\"_blank\">https://wandb.ai/abisheks/assignment2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/abisheks/assignment2/sweeps/mghk051h\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/sweeps/mghk051h</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/abisheks/assignment2/runs/q84iklqp\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/q84iklqp</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210331_191937-q84iklqp</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 9006 files belonging to 10 classes.\n",
            "Found 1004 files belonging to 10 classes.\n",
            "Found 2008 files belonging to 10 classes.\n",
            "Epoch 1/20\n",
            "141/141 - 77s - loss: 4.2053 - accuracy: 0.0940 - val_loss: 2.3028 - val_accuracy: 0.0996\n",
            "Epoch 2/20\n",
            "141/141 - 67s - loss: 2.3035 - accuracy: 0.0929 - val_loss: 2.3027 - val_accuracy: 0.0996\n",
            "Epoch 3/20\n",
            "141/141 - 66s - loss: 2.3034 - accuracy: 0.0869 - val_loss: 2.3027 - val_accuracy: 0.0996\n",
            "Epoch 4/20\n",
            "141/141 - 66s - loss: 2.3034 - accuracy: 0.0918 - val_loss: 2.3028 - val_accuracy: 0.0996\n",
            "Epoch 5/20\n",
            "141/141 - 66s - loss: 2.3033 - accuracy: 0.0927 - val_loss: 2.3027 - val_accuracy: 0.0996\n",
            "Epoch 6/20\n",
            "141/141 - 66s - loss: 2.3034 - accuracy: 0.0908 - val_loss: 2.3027 - val_accuracy: 0.0996\n",
            "Epoch 7/20\n",
            "141/141 - 66s - loss: 2.3033 - accuracy: 0.0920 - val_loss: 2.3028 - val_accuracy: 0.0996\n",
            "Epoch 8/20\n",
            "141/141 - 66s - loss: 2.3033 - accuracy: 0.0926 - val_loss: 2.3028 - val_accuracy: 0.0996\n",
            "Epoch 9/20\n",
            "141/141 - 66s - loss: 2.3034 - accuracy: 0.0912 - val_loss: 2.3027 - val_accuracy: 0.0996\n",
            "Epoch 10/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t75Tu8EmjJOJ",
        "outputId": "f8592e0b-5783-498a-936e-fb2c909d0e6f"
      },
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ":W&B�\u0000�Q\fT\u0003\u0000\u0001�\u0001\u0000\u001c\u0019��\u0013\u0001\u0001�\u0001\u0002\b\u0001�\u0001�\u0001\n",
            "\bprjlufzg\u0012\babisheks\u001a\u000bassignment2\"�\u0001\n",
            "\u001c\n",
            "\u0013batch_normalization�\u0001\u0004true\n",
            "\u0017\n",
            "\u000edata_augmented�\u0001\u0004true\n",
            "\u000f\n",
            "\u0007dropout�\u0001\u00030.2\n",
            " \n",
            "\u0013filter_organization�\u0001\b\"double\"\n",
            "\u0011\n",
            "\n",
            "no_filters�\u0001\u000232\n",
            "\r\n",
            "\u0006_wandb�\u0001\u0002{}j\f810bdbbaadff�\u0001\u0006\b����\u0006�\u0001\u001d\n",
            "\u0004\u0018\u0001(\u0001\"\u00063.7.10*\u00070.10.24B\u0004\b\u0001(\u0001�\u0001 d0bc65748307403687c37b36b0f4da12~�(�\u0019\u0000\u00012\u0017\n",
            "\u0015\n",
            "\u0013wandb-metadata.json\u000fr�\u001e\u0003\u0001\u0001�\u0001�\u0001\n",
            "\bprjlufzg\u0012\babisheks\u001a\u000bassignment2\"�\u0001\n",
            "\u001c\n",
            "\u0013batch_normalization�\u0001\u0004true\n",
            "\u0017\n",
            "\u000edata_augmented�\u0001\u0004true\n",
            "\u000f\n",
            "\u0007dropout�\u0001\u00030.2\n",
            " \n",
            "\u0013filter_organization�\u0001\b\"double\"\n",
            "\u0011\n",
            "\n",
            "no_filters�\u0001\u000232\n",
            "\r\n",
            "\u0006_wandb�\u0001\u0002{}B\u0016nf_32_fo_double_dr_0.2j\f810bdbbaadff�\u0001\u0006\b����\u0006�\u0001\u001d\n",
            "\u0004\u0018\u0001(\u0001\"\u00063.7.10*\u00070.10.24B\u0004\b\u0001(\u0001g�\t\u0014\u0015\u0000\u00012\u0013\n",
            "\u0011\n",
            "\rmodel-best.h5\u0010\u0002�ekb�\u0000\u0001\"�\u0001\b\u0001\u0012\f\b����\u0006\u0010���\u0001\u001a�\u0001Found 9006 files belonging to 10 classes.\n",
            "Found 1004 files belonging to 10 classes.\n",
            "Found 2008 files belonging to 10 classes.\n",
            "Epoch 1/20\n",
            "\u001fT�o�\u0000\u0001\"�\u0001\u0012\f\b����\u0006\u0010����\u0001\u001a�\u0001\u001b[34m\u001b[1mwandb\u001b[39m\u001b[22m: \u001b[33mWARNING\u001b[39m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n",
            "��ŭ-\u0000\u0001Z+\n",
            "\u0004\u0018\u0001(\u0001\u0012\u0004\u0018\u0001(\u0001\u001a\u0006\u0010\u0001\u0018\u0001@\u0001\"\u00063.7.10*\u00070.10.24B\u0004\b\u0001(\u0001�\u000f��\u0005\u0000\u0001�\u0001\u0002\b\u0001}��>�\u0001\u0001:�\u0002\u0012\f\b����\u0006\u0010ا��\u0002\u001a\u0011\n",
            "\tgpu.0.gpu�\u0001\u00030.0\u001a\u0014\n",
            "\fgpu.0.memory�\u0001\u00030.0\u001a\u001e\n",
            "\u0015gpu.0.memoryAllocated�\u0001\u00042.63\u001a\u0013\n",
            "\n",
            "gpu.0.temp�\u0001\u000454.0\u001a\u001a\n",
            "\u0010gpu.0.powerWatts�\u0001\u000529.41\u001a\u001c\n",
            "\u0012gpu.0.powerPercent�\u0001\u000542.02\u001a\r\n",
            "\u0003cpu�\u0001\u000563.05\u001a\u000f\n",
            "\u0006memory�\u0001\u000413.6\u001a,\n",
            "\u0007network�\u0001 {\"sent\": 195725, \"recv\": 358154}\u001a\r\n",
            "\u0004disk�\u0001\u000467.8\u001a$\n",
            "\u0017proc.memory.availableMB�\u0001\b11248.29\u001a\u001b\n",
            "\u0011proc.memory.rssMB�\u0001\u0005316.8\u001a\u001c\n",
            "\u0013proc.memory.percent�\u0001\u00042.43\u001a\u0019\n",
            "\u0010proc.cpu.threads�\u0001\u000413.0�I�N\u0002\u0000\u0001\u001a\u00006\u0000\u001fZ\u0003\u0000\u0001�\u0001\u0000F�9F\u0003\u0000\u0001�\u0001\u0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebkh3kAslcgB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
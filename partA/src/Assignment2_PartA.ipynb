{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment2_PartA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7941003463874c79b98cae9af4939ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29e84fad21994e45ae7e070779f2304b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eede9fe90f9944d6a553c0aeebcd0937",
              "IPY_MODEL_7f0d9e4a60a74aef904c3cc0d4815097"
            ]
          }
        },
        "29e84fad21994e45ae7e070779f2304b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eede9fe90f9944d6a553c0aeebcd0937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_62b22357765e43b28fa0f3cbc50f2b72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 502.63MB of 502.63MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bf91b24852e4b46938090ed7427ee29"
          }
        },
        "7f0d9e4a60a74aef904c3cc0d4815097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c512449527f94434a4152d3654fa7b85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34f34ad94da5471bb61e262c9a374b4d"
          }
        },
        "62b22357765e43b28fa0f3cbc50f2b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bf91b24852e4b46938090ed7427ee29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c512449527f94434a4152d3654fa7b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34f34ad94da5471bb61e262c9a374b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abisubramanya27/CS6910_Assignment2/blob/main/partA/src/Assignment2_PartA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXXJfnO-jhpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32da2093-a85a-4977-e78e-da7866991ea2"
      },
      "source": [
        "# Mounting drive to store dataset\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "#!rm -rf inaturalist_12K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0EP3CrxEbJi",
        "outputId": "1560cbe2-440f-4da0-f685-296ac65eade3"
      },
      "source": [
        "%%time\n",
        "# %cd gdrive/MyDrive/assignments/cs6910/A2/Data\n",
        "# !pwd\n",
        "!cp gdrive/MyDrive/assignments/cs6910/A2/Data/inaturalist_12K.zip .\n",
        "#!gdown --id 11SGStqp8Vug2GDzSpJDwQYHThLIjZFQn\n",
        "!unzip -q inaturalist_12K.zip\n",
        "!ls\n",
        "\n",
        "# import zipfile\n",
        "# import concurrent.futures\n",
        "\n",
        "# zf = zipfile.ZipFile('inaturalist_12K.zip')\n",
        "\n",
        "# def unzip(file):\n",
        "#     zf.extract(file)\n",
        "\n",
        "# with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "#     executor.map(unzip, zf.infolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tinaturalist_12K  inaturalist_12K.zip  sample_data\n",
            "CPU times: user 2.3 s, sys: 299 ms, total: 2.6 s\n",
            "Wall time: 8min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j52r8UJYXr1U"
      },
      "source": [
        "# !pip install split-folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHtrVxShEOOa"
      },
      "source": [
        "# import splitfolders\n",
        "\n",
        "# # Splitting the training data into training and validation set\n",
        "# splitfolders.ratio('./inaturalist_12K/train', output='./inaturalist_12K/output', seed=1337, ratio=(.9, .1), group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cjlDvASXtfR"
      },
      "source": [
        "import os\n",
        "def print_count_classes_in_valid():\n",
        "  class_count_valid = {}\n",
        "  for subdir, dirs, files in os.walk('./inaturalist_12K/val'):\n",
        "      for file in files:\n",
        "        class_count_valid[subdir] = class_count_valid.get(subdir,0)+1\n",
        "\n",
        "  print(class_count_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgiGx6yCuB-Q",
        "outputId": "9d4bc0aa-e02c-412f-ead8-a90f2f41972d"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(physical_devices))\n",
        "\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdy2ocN-wnil"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def build_model_partA(inp_img_shape, K_list, F_list, no_neurons_dense, no_classes = 10, pooling_list = ['max']*5, activation_fn_list = ['relu']*6, \n",
        "                      P_list = ['valid']*10, S_list = [1]*10, reg_list = ['none']*7, lambda_ = 0.01, BN_yes = False, dropout_p = 0):\n",
        "    '''\n",
        "    Function to build the model comprising (5 conv+relu+maxpooling layers + 1 dense FC layer) for part A in keras\n",
        "    Arguments :\n",
        "        inp_img_shape -- shape of input image\n",
        "        K_list -- List of number of filters in each non FC layer\n",
        "        F_list -- List of size of filters (assumed same dimension in width and height) in each non FC layer  \n",
        "        no_neurons_dense -- Number of neurons in the dense FC layer\n",
        "        no_classes -- Number of output classes in the classification problem\n",
        "        pooling_list -- List of pooling layer option for each conv+pooling block ('max' : MaxPooling2D, 'avg': AveragePooling2D)\n",
        "        activation_fn_list -- List of activation function in each convolution layer and the onne hidden FC layer\n",
        "        P_list -- List of padding options in each non FC layer \n",
        "                  ('valid' : no padding, 'same' : padding to make input and output same dimensions)\n",
        "        S_list -- List of strides (assumed equal in width and height) in each non FC layer\n",
        "        reg_list -- List of regularization options for the convolution, one hidden FC and output layers ('none' : no regularization, 'L2' , 'L1')\n",
        "        lambda_ -- weight decay hyperparameter for regularisation\n",
        "        BN_yes -- True : Batch normalisation (BN) should be used, False : BN should not be used\n",
        "        dropout_p -- Probability of dropping out a neuron\n",
        "                     (The dropout is added for the single dense hidden layer alone after referring to many CNN architecture papers)\n",
        "\n",
        "    Returns :\n",
        "        model -- The keras sequential model of the CNN created\n",
        "    '''\n",
        "    get_regularization = {\n",
        "        'none': None,\n",
        "        'L1': regularizers.l1(lambda_),\n",
        "        'L2': regularizers.l2(lambda_)\n",
        "    }\n",
        "\n",
        "    get_pooling_layer = {\n",
        "        'max': MaxPooling2D,\n",
        "        'avg': AveragePooling2D\n",
        "    }\n",
        "\n",
        "    model = Sequential()\n",
        "    # First layer\n",
        "    model.add(Conv2D(filters = K_list[0], kernel_size = (F_list[0], F_list[0]), strides = (S_list[0], S_list[0]), \n",
        "                     padding = P_list[0], input_shape = inp_img_shape, kernel_regularizer = get_regularization[reg_list[0]]))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation_fn_list[0]))\n",
        "    model.add(get_pooling_layer[pooling_list[0]](pool_size=(F_list[1], F_list[1]), strides = (S_list[1], S_list[1]), padding = P_list[1]))\n",
        "\n",
        "    # 4 Conv-relu-MaxPooling layers\n",
        "    for l in range(1, 5):\n",
        "        model.add(Conv2D(filters = K_list[2*l], kernel_size = (F_list[2*l], F_list[2*l]), strides = (S_list[2*l], S_list[2*l]), \n",
        "                         padding = P_list[2*l], kernel_regularizer = get_regularization[reg_list[l]]))\n",
        "        if BN_yes:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Activation(activation_fn_list[l]))\n",
        "        model.add(get_pooling_layer[pooling_list[l]](pool_size = (F_list[2*l+1], F_list[2*l+1]), strides = (S_list[2*l+1], S_list[2*l+1]), padding = P_list[2*l+1]))\n",
        "    \n",
        "    # 1 dense FC layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(dropout_p))\n",
        "    model.add(Dense(units = no_neurons_dense, kernel_regularizer = get_regularization[reg_list[5]]))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation = activation_fn_list[5]))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(units = no_classes, kernel_regularizer = get_regularization[reg_list[6]]))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejgmFIPE_DL5",
        "outputId": "6e5212b2-92e1-4d8d-c665-5ae105613950"
      },
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login 6746f968d95eb71e281d6c7772a0469574430408"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/a0f47563dc06df4dad4db96938d65a10efeb8ea909a423c96a0bfffc845c/wandb-0.10.24-py2.py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 18.4MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 44.6MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.7MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=ac24bfa6278bd5b769061c9028ce59547f0c1e1e2ffc98e6c5f61e4b5b5fee70\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=d6ac5e8508853fafd526d554d3d2bf468264399b98222c3496cf5ac68f7ee44b\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: sentry-sdk, pathtools, shortuuid, smmap, gitdb, GitPython, docker-pycreds, configparser, subprocess32, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T99QShvaRdXa"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Model for resizing and rescaling images\n",
        "image_rescale = Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "# Model for performing random transformations for data augmentation\n",
        "data_augmentation = Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomTranslation(0.2, 0.2),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2, 0.2),\n",
        "    layers.experimental.preprocessing.RandomContrast(0.2)\n",
        "])\n",
        "\n",
        "def prepare_data(data_path, inp_img_shape, batch_size, img_preprocess, data_augmentation, data_augment_yes = False, shuffle = True):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    dataset = image_dataset_from_directory(\n",
        "        data_path, labels='inferred', color_mode='rgb', batch_size=batch_size, image_size=inp_img_shape[:-1], shuffle=shuffle,\n",
        "        seed=123, label_mode='categorical'\n",
        "    )\n",
        "    \n",
        "    dataset = dataset.map(lambda x, y: (img_preprocess(x), y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # Use data augmentation only if data_augment_yes == True (Training set only requires data augmentation)\n",
        "    if data_augment_yes:\n",
        "        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # Use buffered prefecting on datasets\n",
        "    return dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "def data_generator(train_data_path, inp_img_shape, batch_size, data_augment_yes = False, val_data_path = None, test_data_path = None):\n",
        "    train_data = None\n",
        "    if train_data is not None:\n",
        "        train_data = prepare_data(train_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, data_augment_yes)\n",
        "    val_data = None\n",
        "    if val_data_path is not None:\n",
        "        val_data = prepare_data(val_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, False)\n",
        "    test_data = None\n",
        "    if test_data_path is not None:\n",
        "        test_data = prepare_data(test_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, False)\n",
        "    \n",
        "    return train_data, val_data, test_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caaNOC3GEDAX"
      },
      "source": [
        "# def data_generator(train_data_path, inp_img_shape, batch_size, data_augment_yes = False, val_data_path = None, test_data_path = None):\n",
        "#     # Techniques for data augmentation sent to ImageDataGenerator \n",
        "#     data_augment_params = {\n",
        "#         'rotation_range': 25,\n",
        "#         'height_shift_range': 0.2,\n",
        "#         'width_shift_range': 0.2,\n",
        "#         'channel_shift_range': 40,\n",
        "#         'brightness_range': (0.2, 0.7),\n",
        "#         'zoom_range': 0.2,\n",
        "#         'horizontal_flip': True \n",
        "#     }\n",
        "\n",
        "#     train_gen_param = data_augment_params if data_augment_yes else dict()\n",
        "\n",
        "#     # Generators for training, validation and test set image data for Part-A from the respective \n",
        "#     train_generator = ImageDataGenerator(rescale = 1./255, **train_gen_param).flow_from_directory(train_data_path, \n",
        "#                                                                                                   target_size = inp_img_shape[:-1], \n",
        "#                                                                                                   batch_size = batch_size, \n",
        "#                                                                                                   class_mode = 'categorical')\n",
        "#     val_generator = None\n",
        "#     if val_data_path is not None:\n",
        "#         val_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(val_data_path, target_size = inp_img_shape[:-1], \n",
        "#                                                                                  batch_size = batch_size, class_mode = 'categorical')  \n",
        "#     test_generator = None\n",
        "#     if test_data_path is not None:\n",
        "#         test_generator = ImageDataGenerator(rescale = 1./255).flow_from_directory(test_data_path, target_size = inp_img_shape[:-1], \n",
        "#                                                                                   batch_size = batch_size, class_mode = 'categorical')\n",
        "    \n",
        "#     return train_generator, val_generator, test_generator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COdHx5_sFEAr"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eOL2KSnGffH"
      },
      "source": [
        "def train_model(model, train_data, loss_function, optimizer = 'adam', learning_rate = 1e-3, epochs = 10, val_data = None):\n",
        "    if optimizer == 'adam':\n",
        "        model.compile(optimizer = Adam(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'momentum':\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'rmsprop':\n",
        "        model.compile(optimizer = RMSprop(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'nesterov':\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9, nesterov = True), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'nadam':\n",
        "        model.compile(optimizer = Nadam(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "    else:\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "\n",
        "    model.fit(train_data,\n",
        "              epochs = epochs, \n",
        "              validation_data = val_data,\n",
        "              verbose = 2,\n",
        "              callbacks = [WandbCallback(monitor='val_accuracy'), EarlyStopping(monitor='val_accuracy', patience=5)])\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TObFzZAjISbW"
      },
      "source": [
        "def get_klist(start1, factor):\n",
        "    start = start1\n",
        "    vals = []\n",
        "    for i in range(5):\n",
        "        vals.append(start)\n",
        "        vals.append(start)\n",
        "        start = max(int(start*factor), 1)\n",
        "    return vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km5FPE73117I"
      },
      "source": [
        "def test_model(model, test_data):\n",
        "    assert(test_data is not None)\n",
        "    test_loss, test_accuracy = model.evaluate(test_data, use_multiprocessing = True, workers = 4)\n",
        "    test_accuracy = round(test_accuracy*100, 2)\n",
        "    test_loss = round(test_loss, 4)\n",
        "    print(f'Test Accuracy : {test_accuracy} | Test Loss : {test_loss}')\n",
        "\n",
        "    return test_loss, test_accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2In7LU6GaOr"
      },
      "source": [
        "def CNN_train(inp_img_shape, train_data_path, K_list, F_list, config, no_classes = 10, pooling_list = ['max']*5, activation_fn_list = ['relu']*6, \n",
        "              P_list = ['valid']*10, S_list = [1]*10, reg_list = ['none']*7, val_data_path = None, test_data_path = None, \n",
        "              wandb_init = True, load_run = None):\n",
        "    \n",
        "    id = ''\n",
        "    if wandb_init:\n",
        "        id = wandb.util.generate_id()\n",
        "        run = wandb.init(id = id, project=\"assignment2\", entity=\"abisheks\", reinit=True, config=config)\n",
        "        \n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    if load_run is None:\n",
        "        model = build_model_partA(inp_img_shape, K_list, F_list, config['no_neurons_dense'], no_classes, pooling_list, activation_fn_list, \n",
        "                                  P_list, S_list, reg_list, config['weight_decay'], config['batch_normalization'], config['dropout'])\n",
        "    else:\n",
        "        prev_model_file = wandb.restore('model-best.h5', 'abisheks/assignment2/'+load_run)\n",
        "        model = tf.keras.models.load_model(prev_model_file.name)\n",
        "\n",
        "    # model.summary()\n",
        "    train_data, val_data, test_data = data_generator(train_data_path, inp_img_shape, config['batch_size'], config['data_augmented'], \n",
        "                                                     val_data_path, test_data_path)\n",
        "    model = train_model(model, train_data, config['loss_function'], config['optimizer'], config['learning_rate'], config['epochs'], val_data)\n",
        "    \n",
        "    if test_data is not None:\n",
        "        test_loss, test_accuracy = test_model(model, test_data)\n",
        "        wandb.log({'test_accuracy': test_accuracy, 'test_loss': test_loss})\n",
        "\n",
        "    if wandb_init:\n",
        "        run.finish()\n",
        "\n",
        "    return model, id\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isIxc_ytIV_G"
      },
      "source": [
        "# Hyperparameters for building the model for Part-A\n",
        "K_list_1 = [32, 32, 32, 32, 64, 64, 64, 64, 128, 128]           # List of number of filters in each non FC layer\n",
        "F_list_1 = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]                       # List of size of filters in each non FC layer  \n",
        "activation_fn_list_1 = ['relu']*6                               # List of activation function in each convolution and FC layer\n",
        "P_list_1 = ['valid']*10                                         # List of padding options in each non FC layer ('valid' : no padding, 'same' : padding to make input and output same dimensions)\n",
        "S_list_1 = [1, 2, 1, 2, 1, 2, 1, 2, 1, 1]                       # List of number of strides in each non FC layer\n",
        "reg_list_1 = ['L2', 'L2', 'L2', 'L2', 'L2', 'L2', 'L2']         # List of regularization options for the convolution, one hidden FC and output layers ('none' : no regularization, 'L2' , 'L1')\n",
        "inp_img_shape_1 = (227, 227, 3)                                 # Shape of input image from data\n",
        "no_classes_1 = 10                                               # Number of output classes in the classification problem\n",
        "pooling_list_1 = ['max']*4 + ['avg']                            # List of pooling layer option for each conv+pooling block ('max' : MaxPooling2D, 'avg': AveragePooling2D)\n",
        "\n",
        "config_1 = {\n",
        "    \"learning_rate\": 1e-3,                                      # Hyperparameter for updating the parameters in gradient descent\n",
        "    \"epochs\": 10,                                               # Number of epochs to train the model   \n",
        "    \"optimizer\": 'nesterov',                                    # Gradient descent algorithm used for the parameter updation\n",
        "    \"batch_size\": 64,                                           # Batch size used for the optimizer\n",
        "    \"loss_function\": 'categorical_crossentropy',                # Loss function used in the optimizer\n",
        "    \"architecture\": 'CNN',                                      # Type of neural network used\n",
        "    \"dataset\": \"iNaturalist_12K\",                               # Name of dataset\n",
        "    'no_filters': 32,                                           # Number of filters for the first convolution layer\n",
        "    'filter_organization': 1,                                   # The factor by which the number of filters change in the subseqeuent convolution layers\n",
        "    'no_neurons_dense': 64,                                     # Number of neurons in the dense FC layer\n",
        "    'data_augmented': False,                                    # True : Data augmentation is done during training, False : No data augmentation done\n",
        "    'dropout' : 0.2,                                            # Probability of dropping out a neuron in dropout technique\n",
        "    'batch_normalization': True,                                # True : Batch normalisation (BN) should be used, False : BN should not be used\n",
        "    'weight_decay': 0.01,                                       # weight decay hyperparameter for regularization\n",
        "    'F_list': F_list_1,\n",
        "    'activation_fn_list': activation_fn_list_1,\n",
        "    'P_list': P_list_1,\n",
        "    'S_list': S_list_1,\n",
        "    'regularization_list': reg_list_1,\n",
        "    'input_image_shape': inp_img_shape_1,\n",
        "    'pooling_layer_list': pooling_list_1\n",
        "}\n",
        "\n",
        "\n",
        "# PART-A, Question 1 -- Building a model with (5 conv+relu+maxpooling layers + 1 dense FC layer) for image classification objective \n",
        "# modelA, _ = CNN(inp_img_shape_1, './inaturalist_12K/train', get_klist(32, 1.5), F_list_1, config_1, no_classes_1, \n",
        "#                 pooling_list_1, activation_fn_list_1, P_list_1, S_list_1, reg_list_1, './inaturalist_12K/val', './inaturalist_12K/test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSwVfR6wfthS"
      },
      "source": [
        "sweep_config = {\n",
        "    'name': 'CNN',\n",
        "    'method': 'bayes',                   # Possible search : grid, random, bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'no_filters': {\n",
        "            'values': [32, 64]\n",
        "        },\n",
        "        'filter_organization': {\n",
        "            'values': [1, 1.5, 2]\n",
        "        },\n",
        "        'data_augmented': {\n",
        "            'values': [True, False]\n",
        "        },\n",
        "        'dropout' :{\n",
        "            'values': [0, 0.25, 0.4]\n",
        "        },\n",
        "        'batch_normalization': {\n",
        "            'values': [True, False]\n",
        "        },\n",
        "        'no_neurons_dense': {\n",
        "            'values': [32, 64, 256]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['adam', 'nesterov']\n",
        "        },\n",
        "        'weight_decay': {\n",
        "            'values': [0.01, 0.001]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnCtc0c2eMqR"
      },
      "source": [
        "def sweep_wrapper(data_path = './inaturalist_12K'):\n",
        "  \n",
        "    # Wrapper function to call the CNN function for sweeping with different hyperparameters\n",
        "    # loss - (string) Loss function used. Takes values only in ['cross-entropy', 'squared-error']\n",
        "\n",
        "    # Default values for hyper-parameters we're going to sweep over\n",
        "    config_defaults =  {\n",
        "        'no_filters': 32,\n",
        "        'filter_organization': 1,\n",
        "        'data_augmented': True, \n",
        "        'dropout' : 0.2,\n",
        "        'batch_normalization': True,\n",
        "        'no_neurons_dense': 64,\n",
        "        'optimizer': 'nesterov',\n",
        "        'weight_decay': 0.01\n",
        "    }\n",
        "\n",
        "    config_defaults.update(config_1)\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    run = wandb.init(config=config_defaults, reinit=True)\n",
        "\n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "\n",
        "    wandb.run.name = f'nf_{config.no_filters}_fo_{config.filter_organization}_dr_{config.dropout}'\n",
        "    wandb.run.name += '_da' if config.data_augmented else '' \n",
        "    wandb.run.name += '_bn' if config.batch_normalization else ''\n",
        "    wandb.run.save()\n",
        "    print(wandb.run.name)\n",
        "\n",
        "    # Sweep uses L2 regularisation as default as given in the question\n",
        "    modelA, _ = CNN_train(inp_img_shape_1, f'{data_path}/train', get_klist(config.no_filters, config.filter_organization), F_list_1,\n",
        "                    config, no_classes_1, pooling_list_1, activation_fn_list_1, P_list_1, S_list_1, reg_list_1, \n",
        "                    f'{data_path}/val', wandb_init = False)\n",
        "    run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7941003463874c79b98cae9af4939ec7",
            "29e84fad21994e45ae7e070779f2304b",
            "eede9fe90f9944d6a553c0aeebcd0937",
            "7f0d9e4a60a74aef904c3cc0d4815097",
            "62b22357765e43b28fa0f3cbc50f2b72",
            "5bf91b24852e4b46938090ed7427ee29",
            "c512449527f94434a4152d3654fa7b85",
            "34f34ad94da5471bb61e262c9a374b4d"
          ]
        },
        "id": "NL25cORLeRto",
        "outputId": "ad8d29da-8751-4c5d-aabf-792a2fbdc4a4"
      },
      "source": [
        "#sweep_id = wandb.sweep(sweep_config, entity=\"abisheks\", project=\"assignment2\")\n",
        "# sweep_id = \"abisheks/assignment2/1zkoctgf\"\n",
        "# wandb.agent(sweep_id, lambda : sweep_wrapper())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 1u4o1x75\n",
            "Sweep URL: https://wandb.ai/abisheks/assignment2/sweeps/1u4o1x75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: agw53z6s with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmented: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organization: half\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_filters: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabisheks\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.24<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">lucky-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment2\" target=\"_blank\">https://wandb.ai/abisheks/assignment2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/abisheks/assignment2/sweeps/1u4o1x75\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/sweeps/1u4o1x75</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/abisheks/assignment2/runs/agw53z6s\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/agw53z6s</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210401_041700-agw53z6s</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 9006 files belonging to 10 classes.\n",
            "Found 1004 files belonging to 10 classes.\n",
            "Found 2008 files belonging to 10 classes.\n",
            "Epoch 1/20\n",
            "141/141 - 217s - loss: 2.2383 - accuracy: 0.1966 - val_loss: 2.4451 - val_accuracy: 0.1325\n",
            "Epoch 2/20\n",
            "141/141 - 175s - loss: 2.0785 - accuracy: 0.2484 - val_loss: 2.2782 - val_accuracy: 0.1892\n",
            "Epoch 3/20\n",
            "141/141 - 182s - loss: 2.0422 - accuracy: 0.2644 - val_loss: 2.4300 - val_accuracy: 0.2002\n",
            "Epoch 4/20\n",
            "141/141 - 167s - loss: 2.0117 - accuracy: 0.2789 - val_loss: 2.4895 - val_accuracy: 0.2052\n",
            "Epoch 5/20\n",
            "141/141 - 168s - loss: 2.0013 - accuracy: 0.2848 - val_loss: 2.3987 - val_accuracy: 0.2092\n",
            "Epoch 6/20\n",
            "141/141 - 169s - loss: 1.9827 - accuracy: 0.2921 - val_loss: 2.5684 - val_accuracy: 0.1892\n",
            "Epoch 7/20\n",
            "141/141 - 163s - loss: 1.9647 - accuracy: 0.3050 - val_loss: 2.5122 - val_accuracy: 0.2102\n",
            "Epoch 8/20\n",
            "141/141 - 165s - loss: 1.9537 - accuracy: 0.3050 - val_loss: 2.2809 - val_accuracy: 0.2510\n",
            "Epoch 9/20\n",
            "141/141 - 164s - loss: 1.9473 - accuracy: 0.3088 - val_loss: 2.2743 - val_accuracy: 0.2550\n",
            "Epoch 10/20\n",
            "141/141 - 184s - loss: 1.9302 - accuracy: 0.3187 - val_loss: 2.1626 - val_accuracy: 0.2669\n",
            "Epoch 11/20\n",
            "141/141 - 166s - loss: 1.9192 - accuracy: 0.3179 - val_loss: 2.6585 - val_accuracy: 0.1992\n",
            "Epoch 12/20\n",
            "141/141 - 168s - loss: 1.9007 - accuracy: 0.3246 - val_loss: 2.0816 - val_accuracy: 0.2888\n",
            "Epoch 13/20\n",
            "141/141 - 170s - loss: 1.9107 - accuracy: 0.3146 - val_loss: 2.1886 - val_accuracy: 0.2560\n",
            "Epoch 14/20\n",
            "141/141 - 163s - loss: 1.9017 - accuracy: 0.3205 - val_loss: 2.0959 - val_accuracy: 0.2769\n",
            "Epoch 15/20\n",
            "141/141 - 165s - loss: 1.8817 - accuracy: 0.3360 - val_loss: 2.4022 - val_accuracy: 0.2450\n",
            "Epoch 16/20\n",
            "141/141 - 182s - loss: 1.8878 - accuracy: 0.3264 - val_loss: 2.3582 - val_accuracy: 0.2490\n",
            "Epoch 17/20\n",
            "141/141 - 180s - loss: 1.8756 - accuracy: 0.3294 - val_loss: 2.2674 - val_accuracy: 0.2440\n",
            "Epoch 18/20\n",
            "141/141 - 182s - loss: 1.8764 - accuracy: 0.3379 - val_loss: 2.1084 - val_accuracy: 0.2729\n",
            "Epoch 19/20\n",
            "141/141 - 182s - loss: 1.8549 - accuracy: 0.3424 - val_loss: 2.2706 - val_accuracy: 0.2799\n",
            "Epoch 20/20\n",
            "141/141 - 183s - loss: 1.8600 - accuracy: 0.3308 - val_loss: 2.3430 - val_accuracy: 0.2510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 536<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7941003463874c79b98cae9af4939ec7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 502.62MB of 502.62MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210401_041700-agw53z6s/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210401_041700-agw53z6s/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>1.85995</td></tr><tr><td>accuracy</td><td>0.33078</td></tr><tr><td>val_loss</td><td>2.34299</td></tr><tr><td>val_accuracy</td><td>0.251</td></tr><tr><td>_runtime</td><td>3512</td></tr><tr><td>_timestamp</td><td>1617254132</td></tr><tr><td>_step</td><td>19</td></tr><tr><td>best_val_loss</td><td>2.0816</td></tr><tr><td>best_epoch</td><td>11</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▂▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇█▇▇██▇</td></tr><tr><td>val_loss</td><td>▅▃▅▆▅▇▆▃▃▂█▁▂▁▅▄▃▁▃▄</td></tr><tr><td>val_accuracy</td><td>▁▄▄▄▄▄▄▆▆▇▄█▇▇▆▆▆▇█▆</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">lucky-sweep-1</strong>: <a href=\"https://wandb.ai/abisheks/assignment2/runs/agw53z6s\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/agw53z6s</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mxuie7tu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmented: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_organization: half\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_filters: 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.24<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">vocal-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment2\" target=\"_blank\">https://wandb.ai/abisheks/assignment2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/abisheks/assignment2/sweeps/1u4o1x75\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/sweeps/1u4o1x75</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/abisheks/assignment2/runs/mxuie7tu\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/mxuie7tu</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210401_051545-mxuie7tu</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 9006 files belonging to 10 classes.\n",
            "Found 1004 files belonging to 10 classes.\n",
            "Found 2008 files belonging to 10 classes.\n",
            "Epoch 1/20\n",
            "141/141 - 185s - loss: 2.2151 - accuracy: 0.2014 - val_loss: 2.3792 - val_accuracy: 0.1972\n",
            "Epoch 2/20\n",
            "141/141 - 184s - loss: 2.0776 - accuracy: 0.2501 - val_loss: 3.1731 - val_accuracy: 0.1305\n",
            "Epoch 3/20\n",
            "141/141 - 169s - loss: 2.0500 - accuracy: 0.2619 - val_loss: 2.6396 - val_accuracy: 0.1723\n",
            "Epoch 4/20\n",
            "141/141 - 171s - loss: 2.0126 - accuracy: 0.2793 - val_loss: 2.4687 - val_accuracy: 0.1882\n",
            "Epoch 5/20\n",
            "141/141 - 171s - loss: 2.0077 - accuracy: 0.2859 - val_loss: 2.9077 - val_accuracy: 0.2012\n",
            "Epoch 6/20\n",
            "141/141 - 170s - loss: 1.9756 - accuracy: 0.2969 - val_loss: 2.8057 - val_accuracy: 0.2112\n",
            "Epoch 7/20\n",
            "141/141 - 168s - loss: 1.9699 - accuracy: 0.2971 - val_loss: 2.4949 - val_accuracy: 0.2351\n",
            "Epoch 8/20\n",
            "141/141 - 167s - loss: 1.9575 - accuracy: 0.2942 - val_loss: 2.3114 - val_accuracy: 0.2351\n",
            "Epoch 9/20\n",
            "141/141 - 170s - loss: 1.9518 - accuracy: 0.3061 - val_loss: 2.1158 - val_accuracy: 0.2729\n",
            "Epoch 10/20\n",
            "141/141 - 165s - loss: 1.9295 - accuracy: 0.3110 - val_loss: 2.0464 - val_accuracy: 0.2659\n",
            "Epoch 11/20\n",
            "141/141 - 183s - loss: 1.9240 - accuracy: 0.3150 - val_loss: 2.3446 - val_accuracy: 0.2649\n",
            "Epoch 12/20\n",
            "141/141 - 182s - loss: 1.9225 - accuracy: 0.3140 - val_loss: 2.1406 - val_accuracy: 0.3048\n",
            "Epoch 13/20\n",
            "141/141 - 169s - loss: 1.9175 - accuracy: 0.3147 - val_loss: 2.1010 - val_accuracy: 0.2998\n",
            "Epoch 14/20\n",
            "141/141 - 166s - loss: 1.9010 - accuracy: 0.3172 - val_loss: 2.9466 - val_accuracy: 0.1992\n",
            "Epoch 15/20\n",
            "141/141 - 182s - loss: 1.9024 - accuracy: 0.3229 - val_loss: 2.1517 - val_accuracy: 0.2998\n",
            "Epoch 16/20\n",
            "141/141 - 183s - loss: 1.8852 - accuracy: 0.3273 - val_loss: 2.3307 - val_accuracy: 0.3078\n",
            "Epoch 17/20\n",
            "141/141 - 186s - loss: 1.8784 - accuracy: 0.3310 - val_loss: 1.9985 - val_accuracy: 0.3267\n",
            "Epoch 18/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t75Tu8EmjJOJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebkh3kAslcgB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
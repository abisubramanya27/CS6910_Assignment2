{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment2_PartB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "venvB",
      "name": "venvb",
      "language": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "427f0793e6104e4ab06958abb1577716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07e27a53cdb848d1985eb22c76b85724",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36c6830193d5470ba93b87f54f562252",
              "IPY_MODEL_bc6b73e7b9824f669ed4cc3d8ce05dac"
            ]
          }
        },
        "07e27a53cdb848d1985eb22c76b85724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36c6830193d5470ba93b87f54f562252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_41615319bd1c455f83b13254652ce1b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 113.95MB of 113.95MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1961a0aaa284e9e97b0c75cca501243"
          }
        },
        "bc6b73e7b9824f669ed4cc3d8ce05dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3dddc14f41f4cca9336a3f1a681d134",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_699fe3d4886d4b33966c7b2fddcd2f56"
          }
        },
        "41615319bd1c455f83b13254652ce1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1961a0aaa284e9e97b0c75cca501243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3dddc14f41f4cca9336a3f1a681d134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "699fe3d4886d4b33966c7b2fddcd2f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1dfbbd7486474c6a955a3f93bab18e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c409e59a0a0440d80befd8a6f00ef1d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ac075af62c94289ad158e1ddbfdaee4",
              "IPY_MODEL_78291f66162740379aa0542eb37330e3"
            ]
          }
        },
        "2c409e59a0a0440d80befd8a6f00ef1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ac075af62c94289ad158e1ddbfdaee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_d047a27571064e9e92f186d5818aa5de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 142.58MB of 142.58MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07eb5126bfd248fa860a037b8f427db2"
          }
        },
        "78291f66162740379aa0542eb37330e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed51c56c6e7247bbb2a472ea78cb5054",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46a2322f0bc24fedb1c9c0e8c555bdbc"
          }
        },
        "d047a27571064e9e92f186d5818aa5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07eb5126bfd248fa860a037b8f427db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed51c56c6e7247bbb2a472ea78cb5054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46a2322f0bc24fedb1c9c0e8c555bdbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abisubramanya27/CS6910_Assignment2/blob/main/partB/src/Assignment2_PartB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0EP3CrxEbJi",
        "outputId": "44fbe48b-b9eb-4e98-f60d-63abc5812072"
      },
      "source": [
        "%%time\n",
        "# The below code will download the zipped folder in which the original training data has already been split into training and validation with almost equal representation among all classes, and unzip it in the current directory\n",
        "!gdown --id 11SGStqp8Vug2GDzSpJDwQYHThLIjZFQn\n",
        "!unzip -q inaturalist_12K.zip\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11SGStqp8Vug2GDzSpJDwQYHThLIjZFQn\n",
            "To: /Users/abishek_programming/Desktop/CS6910_Assignment2/partB/src/inaturalist_12K.zip\n",
            "7.01GB [17:21, 6.73MB/s]\n",
            "Assignment2_PartB.ipynb inaturalist_12K.zip\n",
            "\u001b[1m\u001b[36minaturalist_12K\u001b[m\u001b[m         \u001b[1m\u001b[36mvenvB\u001b[m\u001b[m\n",
            "CPU times: user 37 s, sys: 11.4 s, total: 48.4 s\n",
            "Wall time: 18min 59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j52r8UJYXr1U"
      },
      "source": [
        "# !pip install split-folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHtrVxShEOOa"
      },
      "source": [
        "# import splitfolders\n",
        "\n",
        "# The code below was used for splitting the training data into training and validation set with equal representations from each class\n",
        "# ---------------------------------- Uncomment below code to split folders once again / check ----------------------------------\n",
        "\n",
        "# splitfolders.ratio('./inaturalist_12K/train', output='./inaturalist_12K', seed=1337, ratio=(.9, .1), group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cjlDvASXtfR"
      },
      "source": [
        "import os\n",
        "def print_count_classes(data_path = './inaturalist_12K/val'):\n",
        "  # Function to check if the images in validation and training set contain nearly equal images belonging to each class\n",
        "  class_count_valid = {}\n",
        "  for subdir, dirs, files in os.walk(data_path):\n",
        "      for file in files:\n",
        "        class_count_valid[subdir] = class_count_valid.get(subdir,0)+1\n",
        "\n",
        "  print(f'In path {data_path} : {class_count_valid}')\n",
        "\n",
        "# --------------------------- Uncomment below code to check count of images in each class in training and validation set ----------------------------\n",
        "\n",
        "# print_count_classes('./inaturalist_12K/val')\n",
        "# print_count_classes('./inaturalist_12K/train')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgiGx6yCuB-Q",
        "outputId": "06c12012-d2cb-493b-d0e7-9761c63fe7fe"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, \\\n",
        "GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(physical_devices))\n",
        "\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdy2ocN-wnil"
      },
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejgmFIPE_DL5",
        "outputId": "9ccea23c-03dc-4ed4-9cc6-1d89f11126ca"
      },
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login 6746f968d95eb71e281d6c7772a0469574430408"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.10.25-py2.py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 617 kB/s \n",
            "\u001b[?25hCollecting psutil>=5.0.0\n",
            "  Using cached psutil-5.8.0-cp37-cp37m-macosx_10_9_x86_64.whl (236 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Using cached shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Processing /Users/abishek_programming/Library/Caches/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2/pathtools-0.1.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in ./venvB/lib/python3.7/site-packages (from wandb) (3.15.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting PyYAML\n",
            "  Using cached PyYAML-5.4.1-cp37-cp37m-macosx_10_9_x86_64.whl (249 kB)\n",
            "Collecting Click>=7.0\n",
            "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in ./venvB/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
            "Processing /Users/abishek_programming/Library/Caches/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d/promise-2.3-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in ./venvB/lib/python3.7/site-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in ./venvB/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
            "Collecting configparser>=3.8.1\n",
            "  Using cached configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Processing /Users/abishek_programming/Library/Caches/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a/subprocess32-3.5.4-py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "  Using cached GitPython-3.1.14-py3-none-any.whl (159 kB)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "  Using cached sentry_sdk-1.0.0-py2.py3-none-any.whl (131 kB)\n",
            "Requirement already satisfied, skipping upgrade: chardet<5,>=3.0.2 in ./venvB/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in ./venvB/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in ./venvB/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.26.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in ./venvB/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Installing collected packages: psutil, shortuuid, pathtools, docker-pycreds, PyYAML, Click, promise, configparser, subprocess32, smmap, gitdb, GitPython, sentry-sdk, wandb\n",
            "Successfully installed Click-7.1.2 GitPython-3.1.14 PyYAML-5.4.1 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 promise-2.3 psutil-5.8.0 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.25\n",
            "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.0.1 is available.\n",
            "You should consider upgrading via the '/Users/abishek_programming/Desktop/CS6910_Assignment2/partB/src/venvB/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/abishek_programming/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T99QShvaRdXa"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Model for resizing and rescaling images\n",
        "image_rescale = Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "# Model for performing random transformations for data augmentation\n",
        "data_augmentation = Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomTranslation(0.2, 0.2),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2, 0.2),\n",
        "    layers.experimental.preprocessing.RandomContrast(0.2)\n",
        "])\n",
        "\n",
        "def prepare_data(data_path, inp_img_shape, batch_size, img_preprocess, data_augmentation, data_augment_yes = False, shuffle = True):\n",
        "    # Function to generate image data after shuffling and forming batches, and applying data augmentation techniques to it randomly\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    dataset = image_dataset_from_directory(\n",
        "        data_path, labels='inferred', color_mode='rgb', batch_size=batch_size, image_size=inp_img_shape[:-1], shuffle=shuffle,\n",
        "        seed=123, label_mode='categorical'\n",
        "    )\n",
        "    \n",
        "    dataset = dataset.map(lambda x, y: (img_preprocess(x), y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # Use data augmentation only if data_augment_yes == True (Training set only requires data augmentation)\n",
        "    if data_augment_yes:\n",
        "        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # Use buffered prefecting on datasets\n",
        "    return dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "def data_generator(inp_img_shape, batch_size, data_augment_yes = False, train_data_path = None, val_data_path = None, test_data_path = None):\n",
        "    # Function to generate training, validation and test data\n",
        "    train_data = None\n",
        "    if train_data_path is not None:\n",
        "        train_data = prepare_data(train_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, data_augment_yes)\n",
        "    val_data = None\n",
        "    if val_data_path is not None:\n",
        "        val_data = prepare_data(val_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, False)\n",
        "    test_data = None\n",
        "    if test_data_path is not None:\n",
        "        test_data = prepare_data(test_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, False)\n",
        "    \n",
        "    return train_data, val_data, test_data\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COdHx5_sFEAr"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eOL2KSnGffH"
      },
      "source": [
        "def train_model(model, train_data, loss_function, optimizer = 'adam', learning_rate = 1e-3, epochs = 10, val_data = None):\n",
        "    # Function to train the model using the mentioned optimizer, learning rate and epochs\n",
        "    if optimizer == 'adam':\n",
        "        model.compile(optimizer = Adam(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'momentum':\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'rmsprop':\n",
        "        model.compile(optimizer = RMSprop(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'nesterov':\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9, nesterov = True), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'nadam':\n",
        "        model.compile(optimizer = Nadam(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "    else:\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "\n",
        "    assert(val_data is not None)\n",
        "    model.fit(train_data,\n",
        "              epochs = epochs, \n",
        "              validation_data = val_data,\n",
        "              verbose = 2,\n",
        "              callbacks = [WandbCallback(monitor='val_accuracy'), EarlyStopping(monitor='val_accuracy', patience=5)])\n",
        "    # Using validation accuracy as the metric to monitor as that is what is intended to be maximized\n",
        "    return model\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebkh3kAslcgB"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "# Get the pretrained function\n",
        "get_pretrained_function = {\n",
        "    'Xception' :          (lambda : tf.keras.applications.xception.Xception(weights='imagenet', include_top=False)),\n",
        "    'ResNet50' :          (lambda : tf.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False)),\n",
        "    'InceptionV3' :       (lambda : tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False)),\n",
        "    'InceptionResNetV2' : (lambda : tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights='imagenet', include_top=False))\n",
        "}\n",
        "\n",
        "# Get the number of layers in each of the pre-trained models to freeze when using transfer learning\n",
        "get_k_value = {\n",
        "    'Xception' :          116,\n",
        "    'ResNet50' :          143,\n",
        "    'InceptionV3' :       249,\n",
        "    'InceptionResNetV2' : 617\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxBKoht1BbGB"
      },
      "source": [
        "def get_pretrained_model(model_name='InceptionResNetV2', no_neurons_dense=1024, k_value=617, no_classes=10):\n",
        "  # Function to get a pre trained model and modify it in aptly to suit our problem\n",
        "  \n",
        "  pretrained_model = get_pretrained_function[model_name]()\n",
        "  # add a global spatial average pooling layer\n",
        "  x = pretrained_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  # let's add a fully-connected layer\n",
        "  x = Dense(no_neurons_dense, activation='relu')(x)\n",
        "  # and a logistic layer -- let's say we have 200 classes\n",
        "  predictions = Dense(no_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=pretrained_model.input, outputs=predictions)\n",
        "  \n",
        "  for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  for layer in model.layers[:k_value]:\n",
        "    layer.trainable = False\n",
        "  for layer in model.layers[k_value:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "  return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqf4IQTp2plw"
      },
      "source": [
        "def test_model(model, test_data):\n",
        "    # Function to get test accuracy and loss for a model on a test data\n",
        "    assert(test_data is not None)\n",
        "    test_loss, test_accuracy = model.evaluate(test_data, use_multiprocessing = True, workers = 4)\n",
        "    test_accuracy = round(test_accuracy*100, 2)\n",
        "    test_loss = round(test_loss, 4)\n",
        "    print(f'Test Accuracy : {test_accuracy} | Test Loss : {test_loss}')\n",
        "\n",
        "    return test_loss, test_accuracy\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x7ioaSrRVUJ"
      },
      "source": [
        "def CNN_pretrained_train(model, inp_img_shape, train_data_path, config, no_classes = 10, val_data_path = None, test_data_path = None, \n",
        "                         wandb_init = True):\n",
        "    '''\n",
        "    Function to train, validate and test a pretrained CNN with specific hyperparameters (and architecture as mentioned in the question), \n",
        "    or test a CNN which was already trained.\n",
        "    (NOTE : the function uses WANDB to log the best model and training metrics)\n",
        "    \n",
        "    Arguments :\n",
        "        model -- (Keras Model object) the pre trained model used for transfer learning\n",
        "        inp_img_shape -- (tuple) shape of input image\n",
        "        train_data_path -- (string) the path to training data set\n",
        "        config -- (dictionary) contains all the hyperparameter and architectural configurations used for the model \n",
        "                  [refer to the config_1 in next cell to see what all it contains]\n",
        "        no_classes -- (int) Number of output classes in the classification problem\n",
        "        val_data_path -- (string) the path to validation data set (though given as optional argument, function would not train if it is not provided)\n",
        "        test_data_path -- (string) the path to test data set. If None, would not evaluate the model on test data set\n",
        "        wandb_init -- (bool) True : WANDB run has been initiated outside the function | False : WANDB run not initiated\n",
        "\n",
        "    Returns :\n",
        "        model -- (Keras Model object) the CNN model which was used for training and/or testing\n",
        "        id -- (string) the unique run ID from WANDB\n",
        "    '''\n",
        "    id = ''\n",
        "    if wandb_init:\n",
        "        id = wandb.util.generate_id()\n",
        "        run = wandb.init(id = id, project=\"assignment2\", entity=\"abisheks\", reinit=True, config=config)\n",
        "        \n",
        "    tf.keras.backend.clear_session()\n",
        "    \n",
        "    assert(train_data_path is not None)\n",
        "    assert(val_data_path is not None)\n",
        "    train_data, val_data, test_data = data_generator(inp_img_shape, config['batch_size'], config['data_augmented'], \n",
        "                                                     train_data_path, val_data_path, test_data_path)\n",
        "    model = train_model(model, train_data, config['loss_function'], config['optimizer'], config['learning_rate'], config['epochs'], val_data)\n",
        "    \n",
        "    if test_data is not None:\n",
        "        test_loss, test_accuracy = test_model(model, test_data)\n",
        "        wandb.log({'test_accuracy': test_accuracy, 'test_loss': test_loss})\n",
        "\n",
        "    if wandb_init:\n",
        "        run.finish()\n",
        "\n",
        "    return model, id\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVJF6Nr6S3-T"
      },
      "source": [
        "# Hyperparameters for building the model for Part-A\n",
        "\n",
        "inp_img_shape_2 = (224, 224, 3)                                 # Shape of input image from data\n",
        "no_classes_2 = 10                                               # Number of output classes in the classification problem\n",
        "\n",
        "# The dictionary that stores all hyperparameter and architectural information about the model. Will be sent to wandb to describe the model in the run\n",
        "config_2 = {\n",
        "    \"learning_rate\": 1e-3,                                      # Hyperparameter for updating the parameters in gradient descent\n",
        "    \"epochs\": 1,                                               # Number of epochs to train the model   \n",
        "    \"optimizer\": 'nesterov',                                    # Gradient descent algorithm used for the parameter updation\n",
        "    \"batch_size\": 64,                                           # Batch size used for the optimizer\n",
        "    \"loss_function\": 'categorical_crossentropy',                # Loss function used in the optimizer\n",
        "    \"no_neurons_dense\": 512,                                    # Number of neurons in the dense FC layer\n",
        "    \"data_augmented\": False,                                    # True : Data augmentation is done during training, False : No data augmentation done\n",
        "    \"model_name\": 'InceptionResNetV2'                           # Name of the pretrained model\n",
        "}\n",
        "\n",
        "\n",
        "# PART-B, Question 1 -- Fine tuning a model pre-trained on Imagenet to iNaturalist dataset\n",
        "# ---------------------------------- To test the CNN_pretrained_train function uncomment the code below ----------------------------------\n",
        "\n",
        "# model = get_pretrained_model(config_2['model_name'], config_2['no_neurons_dense'], get_k_value[config_2['model_name']], no_classes_2)\n",
        "# modelA, _ = CNN_pretrained_train(model, inp_img_shape_2, './inaturalist_12K/train', config_2, no_classes_2, \n",
        "#                                   './inaturalist_12K/val', './inaturalist_12K/test')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 36s 0us/step\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabisheks\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "/Users/abishek_programming/Desktop/CS6910_Assignment2/partB/src/venvB/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
            "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n                Tracking run with wandb version 0.10.25<br/>\n                Syncing run <strong style=\"color:#cdcd00\">azure-wind-527</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/abisheks/assignment2\" target=\"_blank\">https://wandb.ai/abisheks/assignment2</a><br/>\n                Run page: <a href=\"https://wandb.ai/abisheks/assignment2/runs/128qbm8j\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/128qbm8j</a><br/>\n                Run data is saved locally in <code>/Users/abishek_programming/Desktop/CS6910_Assignment2/partB/src/wandb/run-20210410_163440-128qbm8j</code><br/><br/>\n            "
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9006 files belonging to 10 classes.\n",
            "Found 1004 files belonging to 10 classes.\n",
            "Found 2008 files belonging to 10 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-31ceda9b061d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'no_neurons_dense'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_k_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_classes_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m modelA, _ = CNN_pretrained_train(model, inp_img_shape_2, './inaturalist_12K/train', config_2, no_classes_2, \n\u001b[0;32m---> 24\u001b[0;31m                                   './inaturalist_12K/val', './inaturalist_12K/test')\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-9e1130c14e34>\u001b[0m in \u001b[0;36mCNN_pretrained_train\u001b[0;34m(model, inp_img_shape, train_data_path, config, no_classes, val_data_path, test_data_path, wandb_init)\u001b[0m\n\u001b[1;32m     31\u001b[0m     train_data, val_data, test_data = data_generator(inp_img_shape, config['batch_size'], config['data_augmented'], \n\u001b[1;32m     32\u001b[0m                                                      train_data_path, val_data_path, test_data_path)\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-1cf841c8f0ce>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, loss_function, optimizer, learning_rate, epochs, val_data)\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m               callbacks = [WandbCallback(monitor='val_accuracy'), EarlyStopping(monitor='val_accuracy', patience=5)])\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Using validation accuracy as the metric to monitor as that is what is intended to be maximized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/CS6910_Assignment2/partB/src/venvB/lib/python3.7/site-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/CS6910_Assignment2/partB/src/venvB/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/CS6910_Assignment2/partB/src/venvB/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/CS6910_Assignment2/partB/src/venvB/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/CS6910_Assignment2/partB/src/venvB/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/CS6910_Assignment2/partB/src/venvB/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/CS6910_Assignment2/partB/src/venvB/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m~/Desktop/CS6910_Assignment2/partB/src/venvB/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLbzD_laKXuq"
      },
      "source": [
        "# Hyperparameter choices to sweep \n",
        "sweep_config = {\n",
        "    'name': 'CNN_pretrained',\n",
        "    'method': 'bayes',                   # Possible search : grid, random, bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'model_name': {\n",
        "            'values': ['InceptionResNetV2', 'InceptionV3', 'ResNet50' , 'Xception']\n",
        "        },\n",
        "        'data_augmented': {\n",
        "            'values': [True, False]\n",
        "        },\n",
        "        'no_neurons_dense': {\n",
        "            'values': [512,1024]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['adam', 'nesterov', 'rmsprop']\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru5mF5svUwwV"
      },
      "source": [
        "def sweep_wrapper(data_path = './inaturalist_12K'):\n",
        "    # Wrapper function to call the CNN pretrained function for sweeping with different hyperparameters\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    run = wandb.init(config=config_2, reinit=True)\n",
        "\n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "\n",
        "    wandb.run.name = f'mn_{config.model_name}_nd_{config.no_neurons_dense}_op_{config.optimizer}'\n",
        "    wandb.run.name += '_da' if config.data_augmented else '' \n",
        "    wandb.run.save()\n",
        "    print(wandb.run.name)\n",
        "\n",
        "    model = get_pretrained_model(config.model_name, config.no_neurons_dense, get_k_value[config.model_name], no_classes_2)\n",
        "\n",
        "    modelB, _ = CNN_pretrained_train(model, inp_img_shape_2, f'{data_path}/train', config_2, no_classes_2, f'{data_path}/val', wandb_init = False)\n",
        "    run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "427f0793e6104e4ab06958abb1577716",
            "07e27a53cdb848d1985eb22c76b85724",
            "36c6830193d5470ba93b87f54f562252",
            "bc6b73e7b9824f669ed4cc3d8ce05dac",
            "41615319bd1c455f83b13254652ce1b2",
            "a1961a0aaa284e9e97b0c75cca501243",
            "c3dddc14f41f4cca9336a3f1a681d134",
            "699fe3d4886d4b33966c7b2fddcd2f56",
            "1dfbbd7486474c6a955a3f93bab18e87",
            "2c409e59a0a0440d80befd8a6f00ef1d",
            "2ac075af62c94289ad158e1ddbfdaee4",
            "78291f66162740379aa0542eb37330e3",
            "d047a27571064e9e92f186d5818aa5de",
            "07eb5126bfd248fa860a037b8f427db2",
            "ed51c56c6e7247bbb2a472ea78cb5054",
            "46a2322f0bc24fedb1c9c0e8c555bdbc"
          ]
        },
        "id": "doP3NWq8QAc0",
        "outputId": "b496b7a4-16e1-4482-fd54-36e7bb1f86f5"
      },
      "source": [
        "# PART-B, Question 3 -- Sweeping across different sets of hyperparameters\n",
        "# ---------------------------------- To run the sweep uncomment the code below ----------------------------------\n",
        "\n",
        "# sweep_id = wandb.sweep(sweep_config, entity=\"abisheks\", project=\"assignment2\")\n",
        "# wandb.agent(sweep_id, lambda : sweep_wrapper())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m8ziujea with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmented: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: Xception\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_neurons_dense: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabisheks\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.24<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">soft-sweep-81</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment2\" target=\"_blank\">https://wandb.ai/abisheks/assignment2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/abisheks/assignment2/sweeps/nhoqsu5c\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/sweeps/nhoqsu5c</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/abisheks/assignment2/runs/m8ziujea\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/m8ziujea</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210405_152439-m8ziujea</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mn_Xception_nd_512_op_rmsprop\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Found 9006 files belonging to 10 classes.\n",
            "Found 1004 files belonging to 10 classes.\n",
            "Epoch 1/10\n",
            "141/141 - 169s - loss: 2.0527 - accuracy: 0.4013 - val_loss: 1.4478 - val_accuracy: 0.6096\n",
            "Epoch 2/10\n",
            "141/141 - 111s - loss: 1.3287 - accuracy: 0.6841 - val_loss: 0.9466 - val_accuracy: 0.7032\n",
            "Epoch 3/10\n",
            "141/141 - 110s - loss: 0.9491 - accuracy: 0.7206 - val_loss: 0.8717 - val_accuracy: 0.7151\n",
            "Epoch 4/10\n",
            "141/141 - 110s - loss: 0.8210 - accuracy: 0.7455 - val_loss: 0.8351 - val_accuracy: 0.7291\n",
            "Epoch 5/10\n",
            "141/141 - 110s - loss: 0.7518 - accuracy: 0.7582 - val_loss: 0.8069 - val_accuracy: 0.7371\n",
            "Epoch 6/10\n",
            "141/141 - 110s - loss: 0.7016 - accuracy: 0.7700 - val_loss: 0.7840 - val_accuracy: 0.7470\n",
            "Epoch 7/10\n",
            "141/141 - 110s - loss: 0.6578 - accuracy: 0.7855 - val_loss: 0.7640 - val_accuracy: 0.7580\n",
            "Epoch 8/10\n",
            "141/141 - 109s - loss: 0.6210 - accuracy: 0.7942 - val_loss: 0.7508 - val_accuracy: 0.7679\n",
            "Epoch 9/10\n",
            "141/141 - 110s - loss: 0.5873 - accuracy: 0.8090 - val_loss: 0.7408 - val_accuracy: 0.7709\n",
            "Epoch 10/10\n",
            "141/141 - 110s - loss: 0.5577 - accuracy: 0.8153 - val_loss: 0.7309 - val_accuracy: 0.7689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 331<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "427f0793e6104e4ab06958abb1577716",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 113.94MB of 113.94MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210405_152439-m8ziujea/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210405_152439-m8ziujea/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.55771</td></tr><tr><td>accuracy</td><td>0.81535</td></tr><tr><td>val_loss</td><td>0.73091</td></tr><tr><td>val_accuracy</td><td>0.76892</td></tr><tr><td>_runtime</td><td>1170</td></tr><tr><td>_timestamp</td><td>1617637449</td></tr><tr><td>_step</td><td>9</td></tr><tr><td>best_val_accuracy</td><td>0.77092</td></tr><tr><td>best_epoch</td><td>8</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▆▆▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▆▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">soft-sweep-81</strong>: <a href=\"https://wandb.ai/abisheks/assignment2/runs/m8ziujea\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/m8ziujea</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 69me43ta with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmented: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: InceptionV3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_neurons_dense: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.24<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">snowy-sweep-83</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment2\" target=\"_blank\">https://wandb.ai/abisheks/assignment2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/abisheks/assignment2/sweeps/nhoqsu5c\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/sweeps/nhoqsu5c</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/abisheks/assignment2/runs/69me43ta\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/69me43ta</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210405_154421-69me43ta</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mn_InceptionV3_nd_1024_op_rmsprop_da\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 2s 0us/step\n",
            "Found 9006 files belonging to 10 classes.\n",
            "Found 1004 files belonging to 10 classes.\n",
            "Epoch 1/10\n",
            "141/141 - 97s - loss: 1.3863 - accuracy: 0.5827 - val_loss: 0.8580 - val_accuracy: 0.7321\n",
            "Epoch 2/10\n",
            "141/141 - 83s - loss: 0.7056 - accuracy: 0.7766 - val_loss: 0.7697 - val_accuracy: 0.7570\n",
            "Epoch 3/10\n",
            "141/141 - 84s - loss: 0.5224 - accuracy: 0.8360 - val_loss: 0.7386 - val_accuracy: 0.7639\n",
            "Epoch 4/10\n",
            "141/141 - 83s - loss: 0.3819 - accuracy: 0.8851 - val_loss: 0.7415 - val_accuracy: 0.7649\n",
            "Epoch 5/10\n",
            "141/141 - 82s - loss: 0.2784 - accuracy: 0.9224 - val_loss: 0.7528 - val_accuracy: 0.7669\n",
            "Epoch 6/10\n",
            "141/141 - 82s - loss: 0.1938 - accuracy: 0.9486 - val_loss: 0.7657 - val_accuracy: 0.7779\n",
            "Epoch 7/10\n",
            "141/141 - 84s - loss: 0.1317 - accuracy: 0.9730 - val_loss: 0.7928 - val_accuracy: 0.7789\n",
            "Epoch 8/10\n",
            "141/141 - 83s - loss: 0.0897 - accuracy: 0.9836 - val_loss: 0.8233 - val_accuracy: 0.7769\n",
            "Epoch 9/10\n",
            "141/141 - 83s - loss: 0.0614 - accuracy: 0.9902 - val_loss: 0.8436 - val_accuracy: 0.7789\n",
            "Epoch 10/10\n",
            "141/141 - 85s - loss: 0.0428 - accuracy: 0.9956 - val_loss: 0.8692 - val_accuracy: 0.7789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 479<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dfbbd7486474c6a955a3f93bab18e87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 2.36MB of 2.36MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210405_154421-69me43ta/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210405_154421-69me43ta/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.04278</td></tr><tr><td>accuracy</td><td>0.99556</td></tr><tr><td>val_loss</td><td>0.86921</td></tr><tr><td>val_accuracy</td><td>0.77888</td></tr><tr><td>_runtime</td><td>864</td></tr><tr><td>_timestamp</td><td>1617638325</td></tr><tr><td>_step</td><td>9</td></tr><tr><td>best_val_accuracy</td><td>0.77888</td></tr><tr><td>best_epoch</td><td>6</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▄▃▃▂▂▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▄▅▆▇▇████</td></tr><tr><td>val_loss</td><td>▇▃▁▁▂▂▄▆▇█</td></tr><tr><td>val_accuracy</td><td>▁▅▆▆▆█████</td></tr><tr><td>_runtime</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">snowy-sweep-83</strong>: <a href=\"https://wandb.ai/abisheks/assignment2/runs/69me43ta\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/69me43ta</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b7db5tvt with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmented: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: InceptionResNetV2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_neurons_dense: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nesterov\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.24<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">avid-sweep-85</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment2\" target=\"_blank\">https://wandb.ai/abisheks/assignment2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/abisheks/assignment2/sweeps/nhoqsu5c\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/sweeps/nhoqsu5c</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/abisheks/assignment2/runs/b7db5tvt\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/b7db5tvt</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210405_155900-b7db5tvt</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mn_InceptionResNetV2_nd_512_op_nesterov\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 7s 0us/step\n",
            "Found 9006 files belonging to 10 classes.\n",
            "Found 1004 files belonging to 10 classes.\n",
            "Epoch 1/10\n",
            "141/141 - 160s - loss: 1.4275 - accuracy: 0.5898 - val_loss: 0.7939 - val_accuracy: 0.7689\n",
            "Epoch 2/10\n",
            "141/141 - 138s - loss: 0.7432 - accuracy: 0.7770 - val_loss: 0.6986 - val_accuracy: 0.7938\n",
            "Epoch 3/10\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
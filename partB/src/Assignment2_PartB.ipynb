{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment2_PartB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abisubramanya27/CS6910_Assignment2/blob/main/partB/src/Assignment2_PartB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXXJfnO-jhpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16e841e-9b83-4a90-c9a8-ec0a6775a629"
      },
      "source": [
        "# Mounting drive to store dataset\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "#!rm -rf inaturalist_12K"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0EP3CrxEbJi",
        "outputId": "abcdd951-0fe9-49ac-8abb-2e6f0331a11d"
      },
      "source": [
        "%%time\n",
        "# %cd gdrive/MyDrive/assignments/cs6910/A2/Data\n",
        "# !pwd\n",
        "!cp gdrive/MyDrive/assignments/cs6910/A2/Data/inaturalist_12K.zip .\n",
        "#!gdown --id 11SGStqp8Vug2GDzSpJDwQYHThLIjZFQn\n",
        "!unzip -q inaturalist_12K.zip\n",
        "!ls\n",
        "\n",
        "# import zipfile\n",
        "# import concurrent.futures\n",
        "\n",
        "# zf = zipfile.ZipFile('inaturalist_12K.zip')\n",
        "\n",
        "# def unzip(file):\n",
        "#     zf.extract(file)\n",
        "\n",
        "# with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "#     executor.map(unzip, zf.infolist())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tinaturalist_12K  inaturalist_12K.zip  sample_data\n",
            "CPU times: user 2.32 s, sys: 405 ms, total: 2.72 s\n",
            "Wall time: 8min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j52r8UJYXr1U"
      },
      "source": [
        "# !pip install split-folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHtrVxShEOOa"
      },
      "source": [
        "# import splitfolders\n",
        "\n",
        "# # Splitting the training data into training and validation set\n",
        "# splitfolders.ratio('./inaturalist_12K/train', output='./inaturalist_12K/output', seed=1337, ratio=(.9, .1), group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cjlDvASXtfR"
      },
      "source": [
        "import os\n",
        "def print_count_classes_in_valid():\n",
        "  class_count_valid = {}\n",
        "  for subdir, dirs, files in os.walk('./inaturalist_12K/val'):\n",
        "      for file in files:\n",
        "        class_count_valid[subdir] = class_count_valid.get(subdir,0)+1\n",
        "\n",
        "  print(class_count_valid)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgiGx6yCuB-Q",
        "outputId": "20282045-8a28-4eaf-b648-b9b2e779e0f5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, Dropout, \\\n",
        "GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(physical_devices))\n",
        "\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdy2ocN-wnil"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def build_model_partA(inp_img_shape, K_list, F_list, no_neurons_dense, no_classes = 10, pooling_list = ['max']*5, activation_fn_list = ['relu']*6, \n",
        "                      P_list = ['valid']*10, S_list = [1]*10, reg_list = ['none']*7, lambda_ = 0.01, BN_yes = False, dropout_p = 0):\n",
        "    '''\n",
        "    Function to build the model comprising (5 conv+relu+maxpooling layers + 1 dense FC layer) for part A in keras\n",
        "    Arguments :\n",
        "        inp_img_shape -- shape of input image\n",
        "        K_list -- List of number of filters in each non FC layer\n",
        "        F_list -- List of size of filters (assumed same dimension in width and height) in each non FC layer  \n",
        "        no_neurons_dense -- Number of neurons in the dense FC layer\n",
        "        no_classes -- Number of output classes in the classification problem\n",
        "        pooling_list -- List of pooling layer option for each conv+pooling block ('max' : MaxPooling2D, 'avg': AveragePooling2D)\n",
        "        activation_fn_list -- List of activation function in each convolution layer and the onne hidden FC layer\n",
        "        P_list -- List of padding options in each non FC layer \n",
        "                  ('valid' : no padding, 'same' : padding to make input and output same dimensions)\n",
        "        S_list -- List of strides (assumed equal in width and height) in each non FC layer\n",
        "        reg_list -- List of regularization options for the convolution, one hidden FC and output layers ('none' : no regularization, 'L2' , 'L1')\n",
        "        lambda_ -- weight decay hyperparameter for regularisation\n",
        "        BN_yes -- True : Batch normalisation (BN) should be used, False : BN should not be used\n",
        "        dropout_p -- Probability of dropping out a neuron\n",
        "                     (The dropout is added for the single dense hidden layer alone after referring to many CNN architecture papers)\n",
        "\n",
        "    Returns :\n",
        "        model -- The keras sequential model of the CNN created\n",
        "    '''\n",
        "    get_regularization = {\n",
        "        'none': None,\n",
        "        'L1': regularizers.l1(lambda_),\n",
        "        'L2': regularizers.l2(lambda_)\n",
        "    }\n",
        "\n",
        "    get_pooling_layer = {\n",
        "        'max': MaxPooling2D,\n",
        "        'avg': AveragePooling2D\n",
        "    }\n",
        "\n",
        "    model = Sequential()\n",
        "    # First layer\n",
        "    model.add(Conv2D(filters = K_list[0], kernel_size = (F_list[0], F_list[0]), strides = (S_list[0], S_list[0]), \n",
        "                     padding = P_list[0], input_shape = inp_img_shape, kernel_regularizer = get_regularization[reg_list[0]]))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation_fn_list[0]))\n",
        "    model.add(get_pooling_layer[pooling_list[0]](pool_size=(F_list[1], F_list[1]), strides = (S_list[1], S_list[1]), padding = P_list[1]))\n",
        "\n",
        "    # 4 Conv-relu-MaxPooling layers\n",
        "    for l in range(1, 5):\n",
        "        model.add(Conv2D(filters = K_list[2*l], kernel_size = (F_list[2*l], F_list[2*l]), strides = (S_list[2*l], S_list[2*l]), \n",
        "                         padding = P_list[2*l], kernel_regularizer = get_regularization[reg_list[l]]))\n",
        "        if BN_yes:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Activation(activation_fn_list[l]))\n",
        "        model.add(get_pooling_layer[pooling_list[l]](pool_size = (F_list[2*l+1], F_list[2*l+1]), strides = (S_list[2*l+1], S_list[2*l+1]), padding = P_list[2*l+1]))\n",
        "    \n",
        "    # 1 dense FC layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(dropout_p))\n",
        "    model.add(Dense(units = no_neurons_dense, kernel_regularizer = get_regularization[reg_list[5]]))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation = activation_fn_list[5]))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(units = no_classes, kernel_regularizer = get_regularization[reg_list[6]]))\n",
        "    if BN_yes:\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Activation(activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejgmFIPE_DL5",
        "outputId": "8645d845-f693-445f-9570-75a508eaa0e9"
      },
      "source": [
        "!pip install --upgrade wandb\n",
        "!wandb login 6746f968d95eb71e281d6c7772a0469574430408"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/70/a0f47563dc06df4dad4db96938d65a10efeb8ea909a423c96a0bfffc845c/wandb-0.10.24-py2.py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 4.3MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 16.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 27.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.9MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=eb16feda86867369e9757bace4c4dc600e25b7c6f64dff7701b99ff584635d02\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=e6e57e23d3e503c93e30298b2fb6a0cca6c48fb9e306b0a48a5467336c98b393\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: shortuuid, pathtools, sentry-sdk, docker-pycreds, subprocess32, configparser, smmap, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T99QShvaRdXa"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Model for resizing and rescaling images\n",
        "image_rescale = Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "# Model for performing random transformations for data augmentation\n",
        "data_augmentation = Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomTranslation(0.2, 0.2),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2, 0.2),\n",
        "    layers.experimental.preprocessing.RandomContrast(0.2)\n",
        "])\n",
        "\n",
        "def prepare_data(data_path, inp_img_shape, batch_size, img_preprocess, data_augmentation, data_augment_yes = False, shuffle = True):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "    dataset = image_dataset_from_directory(\n",
        "        data_path, labels='inferred', color_mode='rgb', batch_size=batch_size, image_size=inp_img_shape[:-1], shuffle=shuffle,\n",
        "        seed=123, label_mode='categorical'\n",
        "    )\n",
        "    \n",
        "    dataset = dataset.map(lambda x, y: (img_preprocess(x), y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # Use data augmentation only if data_augment_yes == True (Training set only requires data augmentation)\n",
        "    if data_augment_yes:\n",
        "        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    # Use buffered prefecting on datasets\n",
        "    return dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "\n",
        "def data_generator(train_data_path, inp_img_shape, batch_size, data_augment_yes = False, val_data_path = None, test_data_path = None):\n",
        "    train_data = prepare_data(train_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, data_augment_yes)\n",
        "    val_data = None\n",
        "    if val_data_path is not None:\n",
        "        val_data = prepare_data(val_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, False)\n",
        "    test_data = None\n",
        "    if test_data_path is not None:\n",
        "        test_data = prepare_data(test_data_path, inp_img_shape, batch_size, image_rescale, data_augmentation, False)\n",
        "    \n",
        "    return train_data, val_data, test_data\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COdHx5_sFEAr"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eOL2KSnGffH"
      },
      "source": [
        "def train_model(model, train_data, loss_function, optimizer = 'adam', learning_rate = 1e-3, epochs = 10, val_data = None):\n",
        "    if optimizer == 'adam':\n",
        "        model.compile(optimizer = Adam(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'momentum':\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'rmsprop':\n",
        "        model.compile(optimizer = RMSprop(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'nesterov':\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate, momentum = 0.9, nesterov = True), loss = loss_function, metrics = ['accuracy'])\n",
        "    elif optimizer == 'nadam':\n",
        "        model.compile(optimizer = Nadam(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "    else:\n",
        "        model.compile(optimizer = SGD(learning_rate=learning_rate), loss = loss_function, metrics = ['accuracy'])\n",
        "\n",
        "    model.fit(train_data,\n",
        "              epochs = epochs, \n",
        "              validation_data = val_data,\n",
        "              verbose = 2,\n",
        "              callbacks = [WandbCallback(monitor='val_accuracy'), EarlyStopping(monitor='val_accuracy', patience=5)])\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebkh3kAslcgB"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "get_pretrained_function = {\n",
        "    'Xception' :          (lambda : tf.keras.applications.xception.Xception(weights='imagenet', include_top=False)),\n",
        "    'ResNet50' :          (lambda : tf.keras.applications.resnet50.ResNet50(weights='imagenet', include_top=False)),\n",
        "    'InceptionV3' :       (lambda : tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False)),\n",
        "    'InceptionResNetV2' : (lambda : tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights='imagenet', include_top=False))\n",
        "}\n",
        "\n",
        "get_k_value = {\n",
        "    'Xception' :          116,\n",
        "    'ResNet50' :          143,\n",
        "    'InceptionV3' :       249,\n",
        "    'InceptionResNetV2' : 617\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxBKoht1BbGB"
      },
      "source": [
        "def get_pretrained_model(model_name='InceptionResNetV2', no_neurons_dense=1024, k_value=617, no_classes=10):\n",
        "  pretrained_model = get_pretrained_function[model_name]()\n",
        "  # add a global spatial average pooling layer\n",
        "  x = pretrained_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  # let's add a fully-connected layer\n",
        "  x = Dense(no_neurons_dense, activation='relu')(x)\n",
        "  # and a logistic layer -- let's say we have 200 classes\n",
        "  predictions = Dense(no_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=pretrained_model.input, outputs=predictions)\n",
        "  \n",
        "  for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  #for i, layer in enumerate(pretrained_model.layers):\n",
        "  #  print(i, layer.name)\n",
        "\n",
        "  for layer in model.layers[:k_value]:\n",
        "    layer.trainable = False\n",
        "  for layer in model.layers[k_value:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "  return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x7ioaSrRVUJ"
      },
      "source": [
        "def CNN_pretrained(model, inp_img_shape, train_data_path, config, no_classes = 10, val_data_path = None, test_data_path = None, sweep = False, \n",
        "                   wandb_log = True):\n",
        "    \n",
        "    id = ''\n",
        "    if not sweep and wandb_log:\n",
        "        id = wandb.util.generate_id()\n",
        "        run = wandb.init(id = id, project=\"assignment2\", entity=\"abisheks\", reinit=True, config=config)\n",
        "        \n",
        "    tf.keras.backend.clear_session()\n",
        "    \n",
        "    train_data, val_data, test_data = data_generator(train_data_path, inp_img_shape, config['batch_size'], config['data_augmented'], \n",
        "                                                     val_data_path, test_data_path)\n",
        "    model = train_model(model, train_data, config['loss_function'], config['optimizer'], config['learning_rate'], config['epochs'], val_data)\n",
        "    \n",
        "    if test_data is not None:\n",
        "        test_loss, test_accuracy = model.evaluate(test_data, use_multiprocessing = True, workers = 4)\n",
        "        print(f'Test Accuracy : {round(test_accuracy*100, 2)} | Test Loss : {round(test_loss, 4)}')\n",
        "        if wandb_log:\n",
        "            wandb.log({'test_accuracy': round(test_accuracy*100, 2), 'test_loss': round(test_loss, 4)})\n",
        "\n",
        "    if not sweep and wandb_log:\n",
        "        run.finish()\n",
        "\n",
        "    return model, id\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVJF6Nr6S3-T"
      },
      "source": [
        "# Hyperparameters for building the model for Part-A\n",
        "\n",
        "inp_img_shape_2 = (224, 224, 3)                                 # Shape of input image from data\n",
        "no_classes_2 = 10                                               # Number of output classes in the classification problem\n",
        "\n",
        "\n",
        "config_2 = {\n",
        "    \"learning_rate\": 1e-3,                                      # Hyperparameter for updating the parameters in gradient descent\n",
        "    \"epochs\": 10,                                               # Number of epochs to train the model   \n",
        "    \"optimizer\": 'nesterov',                                    # Gradient descent algorithm used for the parameter updation\n",
        "    \"batch_size\": 64,                                           # Batch size used for the optimizer\n",
        "    \"loss_function\": 'categorical_crossentropy',                # Loss function used in the optimizer\n",
        "    \"no_neurons_dense\": 512,                                    # Number of neurons in the dense FC layer\n",
        "    \"data_augmented\": False,                                    # True : Data augmentation is done during training, False : No data augmentation done\n",
        "    \"model_name\": 'InceptionResNetV2'                           # Name of the pretrained model\n",
        "}\n",
        "\n",
        "\n",
        "# PART-B, Question 1 -- Fine tuning a model pre-trained on Imagenet to iNaturalist dataset\n",
        "# model = get_pretrained_model(config_2['model_name'], config_2['no_neurons_dense'], get_k_value[config_2['model_name']], no_classes_2)\n",
        "# modelA, _ = CNN_pretrained(model, inp_img_shape_2, './inaturalist_12K/train', config_2, no_classes_2, './inaturalist_12K/val', './inaturalist_12K/test')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLbzD_laKXuq"
      },
      "source": [
        "sweep_config = {\n",
        "    'name': 'CNN_pretrained',\n",
        "    'method': 'bayes',                   # Possible search : grid, random, bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'model_name': {\n",
        "            'values': ['InceptionResNetV2', 'InceptionV3', 'ResNet50' , 'Xception']\n",
        "        },\n",
        "        'data_augmented': {\n",
        "            'values': [True, False]\n",
        "        },\n",
        "        'no_neurons_dense': {\n",
        "            'values': [512,1024]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['adam', 'nesterov', 'rmsprop']\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru5mF5svUwwV"
      },
      "source": [
        "def sweep_wrapper(data_path = './inaturalist_12K'):\n",
        "  \n",
        "    # Wrapper function to call the CNN pretrained function for sweeping with different hyperparameters\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    run = wandb.init(config=config_2, reinit=True)\n",
        "\n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "    #print(config)\n",
        "\n",
        "    wandb.run.name = f'mn_{config.model_name}_nd_{config.no_neurons_dense}_op_{config.optimizer}'\n",
        "    wandb.run.name += '_da' if config.data_augmented else '' \n",
        "    wandb.run.save()\n",
        "    print(wandb.run.name)\n",
        "    model = get_pretrained_model(config.model_name, config.no_neurons_dense, get_k_value[config.model_name], no_classes_2)\n",
        "    # Sweep uses L2 regularisation as default as given in the question\n",
        "    modelA, _ = CNN_pretrained(model, inp_img_shape_2, f'{data_path}/train', config_2, no_classes_2, f'{data_path}/val', sweep = True, \n",
        "                               wandb_log = True)\n",
        "    run.finish()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "doP3NWq8QAc0",
        "outputId": "1109c209-845d-49ee-fd1a-7b07110f1f40"
      },
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity=\"abisheks\", project=\"assignment2\")\n",
        "# sweep_id = \"abisheks/assignment2/nhoqsu5c\"\n",
        "wandb.agent(sweep_id, lambda : sweep_wrapper())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: nhoqsu5c\n",
            "Sweep URL: https://wandb.ai/abisheks/assignment2/sweeps/nhoqsu5c\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1flth26y with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmented: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: ResNet50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tno_neurons_dense: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.24<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">grateful-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/abisheks/assignment2\" target=\"_blank\">https://wandb.ai/abisheks/assignment2</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/abisheks/assignment2/sweeps/nhoqsu5c\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/sweeps/nhoqsu5c</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/abisheks/assignment2/runs/1flth26y\" target=\"_blank\">https://wandb.ai/abisheks/assignment2/runs/1flth26y</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210404_193221-1flth26y</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mn_ResNet50_nd_512_op_adam_da\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Found 9006 files belonging to 10 classes.\n",
            "Found 1004 files belonging to 10 classes.\n",
            "Epoch 1/10\n",
            "141/141 - 158s - loss: 2.1510 - accuracy: 0.2173 - val_loss: 2.2946 - val_accuracy: 0.1056\n",
            "Epoch 2/10\n",
            "141/141 - 93s - loss: 1.9969 - accuracy: 0.2898 - val_loss: 2.1803 - val_accuracy: 0.1932\n",
            "Epoch 3/10\n",
            "141/141 - 92s - loss: 1.9122 - accuracy: 0.3297 - val_loss: 2.0228 - val_accuracy: 0.2898\n",
            "Epoch 4/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZzuuEqCTSQX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}